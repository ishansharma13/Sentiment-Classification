{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stacking sentiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk9UDC4GVa29"
      },
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.models import load_model,Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers.merge import concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08iGkYCUsh33"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zJR5TyXV1h7"
      },
      "source": [
        "client = storage.Client()\n",
        "# https://console.cloud.google.com/storage/browser/[bucket-id]/\n",
        "bucket = client.get_bucket('stacked-models-tpu')\n",
        "# Then do other things...\n",
        "blob = bucket.get_blob('sentiment/')\n",
        "\n",
        "# print(blob.download_as_string())\n",
        "# blob.upload_from_string('New contents!')\n",
        "# blob2 = bucket.blob('remote/path/storage.txt')\n",
        "# blob2.upload_from_filename(filename='/local/path.txt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BTac4-iVlj5"
      },
      "source": [
        "def load_all_models(names):\n",
        "  with tf.device('/job:localhost'):\n",
        "      # for name in names:\n",
        "      # # define filename for this ensemble\n",
        "      #   filename = '/content/drive/MyDrive/sentiment models/'+name\n",
        "      # # load model from file\n",
        "      # models = [load_model('/content/drive/MyDrive/sarcasm models/'+name) for name in names]\n",
        "    models = [load_model('gs://stacked-models-tpu/sentiment/'+name) for name in names]\n",
        "      # add to list of members\n",
        "        # all_models.append(model)\n",
        "        # print('>loaded %s' % name)\n",
        "  return models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzEHBoMNYRoC"
      },
      "source": [
        "def define_stacked_model(names,members):\n",
        "\t# update all layers in all models to not be trainable\n",
        "  for i in range(len(members)):\n",
        "    model = members[i]\n",
        "    # model.input._name = names[i].replace('.h5','')+'_'+model.input.name\n",
        "    for layer in model.layers:\n",
        "      # make not trainable\n",
        "      layer.trainable = True\n",
        "      # rename to avoid 'unique layer name' issue\n",
        "      layer._name = names[i].replace('.h5','')+'_' + 'ensemble'+'_'+str(i+1) + '_' + layer.name\n",
        "    # define multi-headed input\n",
        "  ensemble_visible = [model.input for model in members]\n",
        "  # concatenate merge output from each model\n",
        "  ensemble_outputs = [model.output for model in members]\n",
        "  merge = concatenate(ensemble_outputs)\n",
        "  hidden = Dense(16, activation='relu')(merge)\n",
        "  output = Dense(5, activation='softmax')(hidden)\n",
        "  model = Model(inputs=ensemble_visible, outputs=output)\n",
        "  # plot graph of ensemble\n",
        "  # plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
        "  # compile\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi5TjeFkaDcl"
      },
      "source": [
        "stacked6 = ['sentiment_CONV1D.h5','sentiment_BiLSTM.h5','sentiment_CONV1D_BiLSTM.h5','sentiment_SEP_CONV1D.h5','sentiment_BiGRU.h5']\n",
        "with strategy.scope():\n",
        "      members = load_all_models(stacked6)\n",
        "      stacked = define_stacked_model(stacked6,members)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liQrhMm4aYzk"
      },
      "source": [
        "# train_data_with_folds_variant_#6.pickle  val_data_with_folds_variant_#6.pickle\n",
        "import pickle\n",
        "with open('train_data_with_folds_variant_#6.pickle','rb') as f:\n",
        "  train_data = pickle.load(f)\n",
        "with open('val_data_with_folds_variant_#6.pickle','rb') as f:\n",
        "  val_data = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5wcmBZmaVwt"
      },
      "source": [
        "for i in range(5):\n",
        "  stacked.fit(x = train_data[i][0],y = train_data[i][1],validation_data=(val_data[i][0],val_data[i][1]),epochs=100,callbacks=[EarlyStopping(monitor='val_loss'),ModelCheckpoint(filepath='trained_sentiment_#6.h5', monitor='val_loss', save_best_only=True))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}