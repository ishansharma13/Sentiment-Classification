{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STACKING FINAL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQxPkKT5Yuq_"
      },
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pprint\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import load_model,Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjwcSB8lY1Nf",
        "outputId": "15b09464-02b3-4614-be11-16596ee5424a"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WacwnZgY41Y",
        "outputId": "2bf1380f-9916-40b9-e787-a3df8cec943e"
      },
      "source": [
        " # for pretty printing our device stats\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "\n",
        "    with tf.compat.v1.Session(tpu_address) as session:\n",
        "      devices = session.list_devices()\n",
        "\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.65.95.82:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 5685545286329333921),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -5398041485626348402),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7715833888834233905),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1235918857523894948),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -4013830805176225422),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -2237730334099227710),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1640355365131669915),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -2107329395461208926),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2207960370495661670),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -2900740931431098420),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 4287767549866722157)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTcn95c8Y7cw",
        "outputId": "0b20fb40-00c0-4802-f1ab-5b261740c99e"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.65.95.82:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.65.95.82:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G0lObVkY-U0"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/FT_300/sentiment/sentiment_params.pickle\",'rb') as file:\n",
        "  ft_file = pickle.load(file)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/GLOVE_100/sentiment/sentiment_params.pickle\",'rb') as file:\n",
        "  gl100_file = pickle.load(file)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/GLOVE_200/sentiment/sentiment_params.pickle\",'rb') as file:\n",
        "  gl200_file = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YEpRteXZWru"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/tr_sen_fin.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6EBko5zZbow"
      },
      "source": [
        "def load_all_models(names):\n",
        "  with tf.device('/job:localhost'):\n",
        "      # for name in names:\n",
        "      # # define filename for this ensemble\n",
        "      #   filename = '/content/drive/MyDrive/sentiment models/'+name\n",
        "      # # load model from file\n",
        "      # models = [load_model('/content/drive/MyDrive/sarcasm models/'+name) for name in names]\n",
        "    models = [load_model('/content/drive/MyDrive/'+name) for name in names]\n",
        "      # add to list of members\n",
        "        # all_models.append(model)\n",
        "        # print('>loaded %s' % name)\n",
        "  return models\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfshBM8sZevc"
      },
      "source": [
        "# from keras.utils import plot_model\n",
        "def define_stacked_model(names,members):\n",
        "\t# update all layers in all models to not be trainable\n",
        "  for i in range(len(members)):\n",
        "    model = members[i]\n",
        "    # model.input._name = names[i].replace('.h5','')+'_'+model.input.name\n",
        "    for layer in model.layers:\n",
        "      # make not trainable\n",
        "      layer.trainable = False\n",
        "      # rename to avoid 'unique layer name' issue\n",
        "      layer._name = names[i].replace('.h5','')+'_' + 'ensemble'+'_'+str(i+1) + '_' + layer.name\n",
        "    # define multi-headed input\n",
        "  ensemble_visible = [model.input for model in members]\n",
        "  # concatenate merge output from each model\n",
        "  ensemble_outputs = [model.output for model in members]\n",
        "  merge = concatenate(ensemble_outputs)\n",
        "  hidden = Dense(16, activation='relu')(merge)\n",
        "  output = Dense(5, activation='softmax')(hidden)\n",
        "  model = Model(inputs=ensemble_visible, outputs=output)\n",
        "  # plot graph of ensemble\n",
        "  # plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
        "  # compile\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6sUNC2PZtUC"
      },
      "source": [
        "def folds(x):\n",
        "  df_tr = df[df['kfold']!=x].reset_index(drop=True)\n",
        "  df_val = df[df['kfold']==x].reset_index(drop=True)\n",
        "  tr_text = df_tr['text'].values\n",
        "  val_text = df_val['text'].values  \n",
        "  x_tr_gl_100 = tf.convert_to_tensor(pad_sequences(gl100_file['Tokenizer'].texts_to_sequences(tr_text),gl100_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "  x_tr_gl_200 = tf.convert_to_tensor(pad_sequences(gl200_file['Tokenizer'].texts_to_sequences(tr_text),gl200_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "  x_tr_ft_300 = tf.convert_to_tensor(pad_sequences(ft_file['Tokenizer'].texts_to_sequences(tr_text),ft_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "\n",
        "\n",
        "  # val_text = df_val['text'].values\n",
        "  x_val_gl_100 = tf.convert_to_tensor(pad_sequences(gl100_file['Tokenizer'].texts_to_sequences(val_text),gl100_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "  x_val_gl_200 = tf.convert_to_tensor(pad_sequences(gl200_file['Tokenizer'].texts_to_sequences(val_text),gl200_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "  x_val_ft_300 = tf.convert_to_tensor(pad_sequences(ft_file['Tokenizer'].texts_to_sequences(val_text),ft_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "\n",
        "  y_val = np_utils.to_categorical(df_val.lbl_num.values)\n",
        "  y_tr = np_utils.to_categorical(df_tr.lbl_num.values)\n",
        "\n",
        "  y_val = tf.convert_to_tensor(y_val,np.float32)\n",
        "  y_tr = tf.convert_to_tensor(y_tr,np.float32)\n",
        "\n",
        "  return {'x_tr_gl_100':x_tr_gl_100,'x_tr_gl_200':x_tr_gl_200,'x_tr_ft_300':x_tr_ft_300,'y_tr':y_tr,'x_val_gl_100':x_val_gl_100,'x_val_gl_200':x_val_gl_200,'x_val_ft_300':x_val_ft_300,'y_val':y_val}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdpw2SmwZwrl"
      },
      "source": [
        "initial_learning_rate = 0.01\n",
        "epochs = 100\n",
        "decay = initial_learning_rate / epochs\n",
        "def lr_time_based_decay(epoch, lr):\n",
        "    return lr * 1 / (1 + decay * epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON49-CSPZz6z"
      },
      "source": [
        "\n",
        "# stacked.fit(x = [x_tr_gl_200,x_tr_gl_100,x_tr_ft_300],y = y_tr,validation_data=([x_val_gl_200,x_val_gl_100,x_val_ft_300],y_val),epochs=100,callbacks=[EarlyStopping()])\n",
        "def train_stacked():\n",
        "  # stacked1 = ['FT_300/sentiment/sentiment_SEP_CONV1D.h5','FT_300/sentiment/sentiment_BiGRU.h5','GLOVE_100/sentiment/sentiment_CONV1D.h5','GLOVE_200/sentiment/sentiment_CONV1D_BiLSTM.h5']\n",
        "  # stacked2 = ['FT_300/sentiment/sentiment_BiLSTM.h5','FT_300/sentiment/sentiment_CONV1D.h5','GLOVE_200/sentiment/sentiment_BiRNN.h5','GLOVE_200/sentiment/sentiment_SEP_CONV1D_BiGRU.h5']\n",
        "  stacked3 = ['FT_300/sentiment/sentiment_CONV1D_BiLSTM.h5','FT_300/sentiment/sentiment_BiGRU.h5','GLOVE_100/sentiment/sentiment_CONV1D_BiRNN.h5','GLOVE_100/sentiment/sentiment_BiRNN.h5']\n",
        "  stacked4 = ['FT_300/sentiment/sentiment_BiLSTM.h5','FT_300/sentiment/sentiment_CONV1D.h5','GLOVE_100/sentiment/sentiment_BiRNN.h5','GLOVE_100/sentiment/sentiment_CONV1D_BiGRU.h5']\n",
        "  # stacked5 = ['FT_300/sentiment/sentiment_CONV1D.h5','GLOVE_100/sentiment/sentiment_BiGRU.h5','GLOVE_200/sentiment/sentiment_CONV1D_BiLSTM.h5','GLOVE_200/sentiment/sentiment_BiLSTM.h5']\n",
        "  # stacked6 = ['FT_300/sentiment/sentiment_CONV1D.h5','FT_300/sentiment/sentiment_BiLSTM.h5','FT_300/sentiment/sentiment_CONV1D_BiLSTM.h5','FT_300/sentiment/sentiment_SEP_CONV1D.h5','FT_300/sentiment/sentiment_BiGRU.h5']\n",
        "  # stacked7 = ['GLOVE_100/sentiment/sentiment_CONV1D.h5','GLOVE_100/sentiment/sentiment_CONV1D_BiRNN.h5','GLOVE_100/sentiment/sentiment_BiRNN.h5','GLOVE_100/sentiment/sentiment_CONV1D_BiGRU.h5','GLOVE_100/sentiment/sentiment_BiGRU.h5']\n",
        "  # stacked8 = ['GLOVE_200/sentiment/sentiment_CONV1D_BiLSTM.h5','GLOVE_200/sentiment/sentiment_BiRNN.h5','GLOVE_200/sentiment/sentiment_SEP_CONV1D_BiGRU.h5','GLOVE_200/sentiment/sentiment_BiLSTM.h5']\n",
        "\n",
        "  model_config = {}\n",
        "  # model_config['STACKED_1'] = (stacked1,['x_tr_ft_300','x_tr_ft_300','x_tr_gl_100','x_tr_gl_200'],['x_val_ft_300','x_val_ft_300','x_val_gl_100','x_val_gl_200']) #300 300 100 200\n",
        "  # model_config['STACKED_2'] = (stacked2,['x_tr_ft_300','x_tr_ft_300','x_tr_gl_200','x_tr_gl_200'],['x_val_ft_300','x_val_ft_300','x_val_gl_200','x_val_gl_200']) #300 300 200 200\n",
        "  model_config['STACKED_3'] = (stacked3,['x_tr_ft_300','x_tr_ft_300','x_tr_gl_100','x_tr_gl_100'],['x_val_ft_300','x_val_ft_300','x_val_gl_100','x_val_gl_100']) #300 300 100 100\n",
        "  model_config['STACKED_4'] = (stacked4,['x_tr_ft_300','x_tr_ft_300','x_tr_gl_100','x_tr_gl_100'],['x_val_ft_300','x_val_ft_300','x_val_gl_100','x_val_gl_100']) #300 300 100 100\n",
        "  # model_config['STACKED_5'] = (stacked5,['x_tr_ft_300','x_tr_gl_100','x_tr_gl_200','x_tr_gl_200'],['x_val_ft_300','x_val_ft_300','x_val_gl_100','x_val_gl_100']) #300 100 200 200\n",
        "  # model_config['STACKED_6'] = (stacked6,['x_tr_ft_300','x_tr_ft_300','x_tr_ft_300','x_tr_ft_300','x_tr_ft_300'],['x_val_ft_300','x_val_ft_300','x_val_ft_300','x_val_ft_300','x_val_ft_300']) #300 300 300 300 300\n",
        "  # model_config['STACKED_7'] = (stacked7,['x_tr_gl_100','x_tr_gl_100','x_tr_gl_100','x_tr_gl_100','x_tr_gl_100'],['x_val_gl_100','x_val_gl_100','x_val_gl_100','x_val_gl_100','x_val_gl_100']) #100 100 100 100 100\n",
        "  # model_config['STACKED_8'] = (stacked8,['x_tr_gl_200','x_tr_gl_200','x_tr_gl_200','x_tr_gl_200'],['x_val_gl_200','x_val_gl_200','x_val_gl_200','x_val_gl_200']) #200 200 200 200 \n",
        "\n",
        "  for k,v in model_config.items():\n",
        "    with strategy.scope():\n",
        "      members = load_all_models(v[0])\n",
        "      stacked = define_stacked_model(v[0],members)\n",
        "    \n",
        "    plot_model(stacked, show_shapes=True, to_file='/content/drive/MyDrive/STACKED/sentiment/sentiment_'+k+'.png')\n",
        "    print(\"----------------------::  TRAINING STARTED :- \"+k+\" ::----------------------\\n\")\n",
        "    for i in range(5):\n",
        "      print(\"-----------:: FOLD :- \"+str(i+1)+' ::-----------')\n",
        "      data = folds(i)\n",
        "      x_t = [data[x] for x in v[1]]\n",
        "      y_t = data['y_tr']\n",
        "      x_v = [data[x] for x in v[2]]\n",
        "      y_v = data['y_val']\n",
        "      stacked.fit(x = x_t,y = y_t,validation_data=(x_v,y_v),epochs=100,callbacks=[EarlyStopping(monitor='val_loss',patience=2),ModelCheckpoint(filepath='/content/drive/MyDrive/STACKED/sentiment/sentiment_'+k+'.h5', monitor='val_loss', save_best_only=True),LearningRateScheduler(lr_time_based_decay,verbose=1)])\n",
        "    print(\"----------------------::  TRAINING COMPLETED :- \"+k+\" ::----------------------\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrH68NjFavGs",
        "outputId": "d9a3cf55-421f-4c13-fc73-d72c92f7d5a5"
      },
      "source": [
        "train_stacked()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------::  TRAINING STARTED :- STACKED_3 ::----------------------\n",
            "\n",
            "-----------:: FOLD :- 1 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "17250/17250 [==============================] - 563s 30ms/step - loss: 0.5216 - accuracy: 0.8255 - val_loss: 0.4977 - val_accuracy: 0.8274\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009999000574917021.\n",
            "17250/17250 [==============================] - 504s 29ms/step - loss: 0.4525 - accuracy: 0.8442 - val_loss: 0.4936 - val_accuracy: 0.8272\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000999700106714659.\n",
            "17250/17250 [==============================] - 504s 29ms/step - loss: 0.4504 - accuracy: 0.8434 - val_loss: 0.4903 - val_accuracy: 0.8261\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009994003415259673.\n",
            "17250/17250 [==============================] - 502s 29ms/step - loss: 0.4441 - accuracy: 0.8443 - val_loss: 0.4895 - val_accuracy: 0.8283\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009990007918579775.\n",
            "17250/17250 [==============================] - 503s 29ms/step - loss: 0.4426 - accuracy: 0.8445 - val_loss: 0.4849 - val_accuracy: 0.8273\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0009985014876310735.\n",
            "17250/17250 [==============================] - 503s 29ms/step - loss: 0.4440 - accuracy: 0.8435 - val_loss: 0.4881 - val_accuracy: 0.8272\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0009979026914447063.\n",
            "12084/17250 [====================>.........] - ETA: 1:57 - loss: 0.4427 - accuracy: 0.8446"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}