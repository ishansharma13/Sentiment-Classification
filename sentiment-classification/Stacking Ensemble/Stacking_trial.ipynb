{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking trial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3E9JGGnN4Wd"
      },
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pprint\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import load_model,Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDwfhY61trI5",
        "outputId": "a1435704-3b77-433e-d731-d04e6514cf62"
      },
      "source": [
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNPcesEhIdr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031591e2-35f2-453f-e6c5-ee9fcd61053d"
      },
      "source": [
        " # for pretty printing our device stats\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "\n",
        "    with tf.compat.v1.Session(tpu_address) as session:\n",
        "      devices = session.list_devices()\n",
        "\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.27.96.50:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 7369304745454012255),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -3219567743174558984),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -1561601111619124330),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -7338362977615657662),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -6876150849496566102),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1599602500828088086),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 233774835397318511),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1217812115579935014),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2688218843983487049),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2484998349240449760),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -6037976665699275646)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ9RcFiXIeii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e10b088-8ed7-4989-8e7c-f22033a95c94"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.27.96.50:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.27.96.50:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hsaNH2RfDFc"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/FT_300/sarcasm/sarcasm_params.pickle\",'rb') as file:\n",
        "  ft_file = pickle.load(file)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/GLOVE_100/sarcasm/sarcasm_params.pickle\",'rb') as file:\n",
        "  gl100_file = pickle.load(file)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/GLOVE_200/sarcasm/sarcasm_params.pickle\",'rb') as file:\n",
        "  gl200_file = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91lyzMbNutZz"
      },
      "source": [
        "\n",
        "# df = pd.read_csv('/content/drive/MyDrive/sentiment data/tr_sen_fin.csv')\n",
        "df = pd.read_csv('/content/drive/MyDrive/datasets/train_sarc_final_with_folds.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJhwxrogvHyN"
      },
      "source": [
        "df_tr = df[df['kfold']!=1].reset_index(drop=True)\n",
        "df_val = df[df['kfold']==1].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTISCrsOvQUW"
      },
      "source": [
        "tr_text = df_tr['text'].values\n",
        "val_text = df_val['text'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFQTU2zwCSQ"
      },
      "source": [
        "\n",
        "y_val = np_utils.to_categorical(df_val.lbl_num.values)\n",
        "y_tr = np_utils.to_categorical(df_tr.lbl_num.values)\n",
        "\n",
        "y_val = tf.convert_to_tensor(y_val,np.float32)\n",
        "y_tr = tf.convert_to_tensor(y_tr,np.float32)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htctf3wcxH8I"
      },
      "source": [
        "# names = ['GLOVE_200D_BiLSTM.h5','GLOVE_100D_CONV1D_BiGRU.h5','FT_300D_CONV1D.h5']\n",
        "# 'GLOVE_100D_CONV_1D_BiGRU.h5'\n",
        "# names = ['FT_300/sarcasm/sarcasm_SEP_CONV1D.h5','FT_300/sarcasm/sarcasm_BiGRU.h5','GLOVE_100/sarcasm/sarcasm_CONV1D.h5','GLOVE_200/sarcasm/sarcasm_CONV1D_BiLSTM.h5']\n",
        "names = ['FT_300/sarcasm/sarcasm_BiLSTM.h5','FT_300/sarcasm/sarcasm_CONV1D.h5','GLOVE_200/sarcasm/sarcasm_BiRNN.h5','GLOVE_200/sarcasm/sarcasm_SEP_CONV1D_BiGRU.h5']\n",
        "# members = load_all_models(names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yN7SSxrxK70"
      },
      "source": [
        "def load_all_models(names):\n",
        "  with tf.device('/job:localhost'):\n",
        "      # for name in names:\n",
        "      # # define filename for this ensemble\n",
        "      #   filename = '/content/drive/MyDrive/sentiment models/'+name\n",
        "      # # load model from file\n",
        "      # models = [load_model('/content/drive/MyDrive/sarcasm models/'+name) for name in names]\n",
        "    models = [load_model('/content/drive/MyDrive/'+name) for name in names]\n",
        "      # add to list of members\n",
        "        # all_models.append(model)\n",
        "        # print('>loaded %s' % name)\n",
        "  return models\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-yriCUwwtrV"
      },
      "source": [
        "# from keras.utils import plot_model\n",
        "def define_stacked_model(names,members):\n",
        "\t# update all layers in all models to not be trainable\n",
        "  for i in range(len(members)):\n",
        "    model = members[i]\n",
        "    # model.input._name = names[i].replace('.h5','')+'_'+model.input.name\n",
        "    for layer in model.layers:\n",
        "      # make not trainable\n",
        "      layer.trainable = False\n",
        "      # rename to avoid 'unique layer name' issue\n",
        "      layer._name = names[i].replace('.h5','')+'_' + 'ensemble'+'_'+str(i+1) + '_' + layer.name\n",
        "    # define multi-headed input\n",
        "  ensemble_visible = [model.input for model in members]\n",
        "  # concatenate merge output from each model\n",
        "  ensemble_outputs = [model.output for model in members]\n",
        "  merge = concatenate(ensemble_outputs)\n",
        "  hidden = Dense(4, activation='relu')(merge)\n",
        "  output = Dense(2, activation='softmax')(hidden)\n",
        "  model = Model(inputs=ensemble_visible, outputs=output)\n",
        "  # plot graph of ensemble\n",
        "  plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
        "  # compile\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr0IQZK0KDDy"
      },
      "source": [
        "with strategy.scope():\n",
        "  members = load_all_models(names)\n",
        "  stacked = define_stacked_model(members)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56IObh0mz3qi"
      },
      "source": [
        "plot_model(stacked, show_shapes=True, to_file='model_graph.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R71s1OAwxaj"
      },
      "source": [
        "def folds(x):\n",
        "  df_tr = df[df['kfold']!=x].reset_index(drop=True)\n",
        "  df_val = df[df['kfold']==x].reset_index(drop=True)\n",
        "  tr_text = df_tr['text'].values\n",
        "  val_text = df_val['text'].values  \n",
        "  x_tr_gl_100 = tf.convert_to_tensor(pad_sequences(gl100_file['Tokenizer'].texts_to_sequences(tr_text),gl100_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "  x_tr_gl_200 = tf.convert_to_tensor(pad_sequences(gl200_file['Tokenizer'].texts_to_sequences(tr_text),gl200_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "  x_tr_ft_300 = tf.convert_to_tensor(pad_sequences(ft_file['Tokenizer'].texts_to_sequences(tr_text),ft_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "\n",
        "\n",
        "  # val_text = df_val['text'].values\n",
        "  x_val_gl_100 = tf.convert_to_tensor(pad_sequences(gl100_file['Tokenizer'].texts_to_sequences(val_text),gl100_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "  x_val_gl_200 = tf.convert_to_tensor(pad_sequences(gl200_file['Tokenizer'].texts_to_sequences(val_text),gl200_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "  x_val_ft_300 = tf.convert_to_tensor(pad_sequences(ft_file['Tokenizer'].texts_to_sequences(val_text),ft_file['long_sen_num'], padding='post',truncating = 'post'),np.int32)\n",
        "\n",
        "  y_val = np_utils.to_categorical(df_val.lbl_num.values)\n",
        "  y_tr = np_utils.to_categorical(df_tr.lbl_num.values)\n",
        "\n",
        "  y_val = tf.convert_to_tensor(y_val,np.float32)\n",
        "  y_tr = tf.convert_to_tensor(y_tr,np.float32)\n",
        "\n",
        "  return {'x_tr_gl_100':x_tr_gl_100,'x_tr_gl_200':x_tr_gl_200,'x_tr_ft_300':x_tr_ft_300,'y_tr':y_tr,'x_val_gl_100':x_val_gl_100,'x_val_gl_200':x_val_gl_200,'x_val_ft_300':x_val_ft_300,'y_val':y_val}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk4-j-WHnrhT"
      },
      "source": [
        "initial_learning_rate = 0.01\n",
        "epochs = 100\n",
        "decay = initial_learning_rate / epochs\n",
        "def lr_time_based_decay(epoch, lr):\n",
        "    return lr * 1 / (1 + decay * epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yeGkWxqf0Yb"
      },
      "source": [
        "\n",
        "# stacked.fit(x = [x_tr_gl_200,x_tr_gl_100,x_tr_ft_300],y = y_tr,validation_data=([x_val_gl_200,x_val_gl_100,x_val_ft_300],y_val),epochs=100,callbacks=[EarlyStopping()])\n",
        "def train_stacked():\n",
        "  stacked1 = ['FT_300/sarcasm/sarcasm_SEP_CONV1D.h5','FT_300/sarcasm/sarcasm_BiGRU.h5','GLOVE_100/sarcasm/sarcasm_CONV1D.h5','GLOVE_200/sarcasm/sarcasm_CONV1D_BiLSTM.h5']\n",
        "  stacked2 = ['FT_300/sarcasm/sarcasm_BiLSTM.h5','FT_300/sarcasm/sarcasm_CONV1D.h5','GLOVE_200/sarcasm/sarcasm_BiRNN.h5','GLOVE_200/sarcasm/sarcasm_SEP_CONV1D_BiGRU.h5']\n",
        "  stacked3 = ['FT_300/sarcasm/sarcasm_CONV1D_BiLSTM.h5','FT_300/sarcasm/sarcasm_BiGRU.h5','GLOVE_100/sarcasm/sarcasm_CONV1D_BiRNN.h5','GLOVE_100/sarcasm/sarcasm_BiRNN.h5']\n",
        "  stacked4 = ['FT_300/sarcasm/sarcasm_BiLSTM.h5','FT_300/sarcasm/sarcasm_CONV1D.h5','GLOVE_100/sarcasm/sarcasm_BiRNN.h5','GLOVE_100/sarcasm/sarcasm_CONV1D_BiGRU.h5']\n",
        "  stacked5 = ['FT_300/sarcasm/sarcasm_CONV1D.h5','GLOVE_100/sarcasm/sarcasm_BiGRU.h5','GLOVE_200/sarcasm/sarcasm_CONV1D_BiLSTM.h5','GLOVE_200/sarcasm/sarcasm_BiLSTM.h5']\n",
        "  stacked6 = ['FT_300/sarcasm/sarcasm_CONV1D.h5','FT_300/sarcasm/sarcasm_BiLSTM.h5','FT_300/sarcasm/sarcasm_CONV1D_BiLSTM.h5','FT_300/sarcasm/sarcasm_SEP_CONV1D.h5','FT_300/sarcasm/sarcasm_BiGRU.h5']\n",
        "  stacked7 = ['GLOVE_100/sarcasm/sarcasm_CONV1D.h5','GLOVE_100/sarcasm/sarcasm_CONV1D_BiRNN.h5','GLOVE_100/sarcasm/sarcasm_BiRNN.h5','GLOVE_100/sarcasm/sarcasm_CONV1D_BiGRU.h5','GLOVE_100/sarcasm/sarcasm_BiGRU.h5']\n",
        "  stacked8 = ['GLOVE_200/sarcasm/sarcasm_CONV1D_BiLSTM.h5','GLOVE_200/sarcasm/sarcasm_BiRNN.h5','GLOVE_200/sarcasm/sarcasm_SEP_CONV1D_BiGRU.h5','GLOVE_200/sarcasm/sarcasm_BiLSTM.h5']\n",
        "\n",
        "  model_config = {}\n",
        "  # model_config['STACKED_1'] = (stacked1,['x_tr_ft_300','x_tr_ft_300','x_tr_gl_100','x_tr_gl_200'],['x_val_ft_300','x_val_ft_300','x_val_gl_100','x_val_gl_200']) #300 300 100 200\n",
        "  # model_config['STACKED_2'] = (stacked2,['x_tr_ft_300','x_tr_ft_300','x_tr_gl_200','x_tr_gl_200'],['x_val_ft_300','x_val_ft_300','x_val_gl_200','x_val_gl_200']) #300 300 200 200\n",
        "  # model_config['STACKED_3'] = (stacked3,['x_tr_ft_300','x_tr_ft_300','x_tr_gl_100','x_tr_gl_100'],['x_val_ft_300','x_val_ft_300','x_val_gl_100','x_val_gl_100']) #300 300 100 100\n",
        "  # model_config['STACKED_4'] = (stacked4,['x_tr_ft_300','x_tr_ft_300','x_tr_gl_100','x_tr_gl_100'],['x_val_ft_300','x_val_ft_300','x_val_gl_100','x_val_gl_100']) #300 300 100 100\n",
        "  # model_config['STACKED_5'] = (stacked5,['x_tr_ft_300','x_tr_gl_100','x_tr_gl_200','x_tr_gl_200'],['x_val_ft_300','x_val_ft_300','x_val_gl_100','x_val_gl_100']) #300 100 200 200\n",
        "  model_config['STACKED_6'] = (stacked6,['x_tr_ft_300','x_tr_ft_300','x_tr_ft_300','x_tr_ft_300','x_tr_ft_300'],['x_val_ft_300','x_val_ft_300','x_val_ft_300','x_val_ft_300','x_val_ft_300']) #300 300 300 300 300\n",
        "  model_config['STACKED_7'] = (stacked7,['x_tr_gl_100','x_tr_gl_100','x_tr_gl_100','x_tr_gl_100','x_tr_gl_100'],['x_val_gl_100','x_val_gl_100','x_val_gl_100','x_val_gl_100','x_val_gl_100']) #100 100 100 100 100\n",
        "  model_config['STACKED_8'] = (stacked8,['x_tr_gl_200','x_tr_gl_200','x_tr_gl_200','x_tr_gl_200'],['x_val_gl_200','x_val_gl_200','x_val_gl_200','x_val_gl_200']) #200 200 200 200 \n",
        "\n",
        "  for k,v in model_config.items():\n",
        "    with strategy.scope():\n",
        "      members = load_all_models(v[0])\n",
        "      stacked = define_stacked_model(v[0],members)\n",
        "    \n",
        "    plot_model(stacked, show_shapes=True, to_file='/content/drive/MyDrive/STACKED/sarcasm/sarcasm_'+k+'.png')\n",
        "    print(\"----------------------::  TRAINING STARTED :- \"+k+\" ::----------------------\\n\")\n",
        "    for i in range(5):\n",
        "      print(\"-----------:: FOLD :- \"+str(i+1)+' ::-----------')\n",
        "      data = folds(i)\n",
        "      x_t = [data[x] for x in v[1]]\n",
        "      y_t = data['y_tr']\n",
        "      x_v = [data[x] for x in v[2]]\n",
        "      y_v = data['y_val']\n",
        "      stacked.fit(x = x_t,y = y_t,validation_data=(x_v,y_v),epochs=100,callbacks=[EarlyStopping(monitor='val_loss',patience=2),ModelCheckpoint(filepath='/content/drive/MyDrive/STACKED/sarcasm/sarcasm_'+k+'.h5', monitor='val_loss', save_best_only=True),LearningRateScheduler(lr_time_based_decay,verbose=1)])\n",
        "    print(\"----------------------::  TRAINING COMPLETED :- \"+k+\" ::----------------------\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_2nXvqYyTkP",
        "outputId": "3ddf388c-bb26-403f-b406-889bc64c2a61"
      },
      "source": [
        "train_stacked()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------::  TRAINING STARTED :- STACKED_6 ::----------------------\n",
            "\n",
            "-----------:: FOLD :- 1 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "7350/7350 [==============================] - 276s 31ms/step - loss: 0.2579 - accuracy: 0.9044 - val_loss: 0.2826 - val_accuracy: 0.8845\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009999000574917021.\n",
            "7350/7350 [==============================] - 224s 30ms/step - loss: 0.2295 - accuracy: 0.9058 - val_loss: 0.2835 - val_accuracy: 0.8847\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000999700106714659.\n",
            "7350/7350 [==============================] - 220s 30ms/step - loss: 0.2298 - accuracy: 0.9060 - val_loss: 0.2837 - val_accuracy: 0.8849\n",
            "-----------:: FOLD :- 2 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009997001616284251.\n",
            "7350/7350 [==============================] - 224s 30ms/step - loss: 0.2442 - accuracy: 0.9003 - val_loss: 0.2248 - val_accuracy: 0.9085\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009996002016082644.\n",
            "7350/7350 [==============================] - 226s 31ms/step - loss: 0.2437 - accuracy: 0.9004 - val_loss: 0.2242 - val_accuracy: 0.9085\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009994002808108137.\n",
            "7350/7350 [==============================] - 224s 31ms/step - loss: 0.2438 - accuracy: 0.9002 - val_loss: 0.2239 - val_accuracy: 0.9086\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009991005455957202.\n",
            "7350/7350 [==============================] - 226s 31ms/step - loss: 0.2442 - accuracy: 0.9002 - val_loss: 0.2240 - val_accuracy: 0.9085\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009987010258953365.\n",
            "7350/7350 [==============================] - 223s 30ms/step - loss: 0.2440 - accuracy: 0.8998 - val_loss: 0.2233 - val_accuracy: 0.9084\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.000998201867987191.\n",
            "7350/7350 [==============================] - 226s 31ms/step - loss: 0.2440 - accuracy: 0.9002 - val_loss: 0.2268 - val_accuracy: 0.9075\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.000997603334435851.\n",
            "7350/7350 [==============================] - 223s 30ms/step - loss: 0.2440 - accuracy: 0.9001 - val_loss: 0.2254 - val_accuracy: 0.9080\n",
            "-----------:: FOLD :- 3 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009976032888516784.\n",
            "7350/7350 [==============================] - 224s 30ms/step - loss: 0.2430 - accuracy: 0.9007 - val_loss: 0.2258 - val_accuracy: 0.9082\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009975035384978286.\n",
            "7350/7350 [==============================] - 224s 31ms/step - loss: 0.2431 - accuracy: 0.9003 - val_loss: 0.2256 - val_accuracy: 0.9082\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000997304060108851.\n",
            "7350/7350 [==============================] - 225s 31ms/step - loss: 0.2436 - accuracy: 0.9005 - val_loss: 0.2253 - val_accuracy: 0.9084\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009970049999745909.\n",
            "7350/7350 [==============================] - 225s 31ms/step - loss: 0.2433 - accuracy: 0.9003 - val_loss: 0.2257 - val_accuracy: 0.9081\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009966063879576267.\n",
            "7350/7350 [==============================] - 223s 30ms/step - loss: 0.2435 - accuracy: 0.9002 - val_loss: 0.2263 - val_accuracy: 0.9081\n",
            "-----------:: FOLD :- 4 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009966064244508743.\n",
            "7350/7350 [==============================] - 223s 30ms/step - loss: 0.2434 - accuracy: 0.9000 - val_loss: 0.2246 - val_accuracy: 0.9085\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.000996506773773497.\n",
            "7350/7350 [==============================] - 225s 31ms/step - loss: 0.2436 - accuracy: 0.9000 - val_loss: 0.2249 - val_accuracy: 0.9084\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009963075114331039.\n",
            "7350/7350 [==============================] - 223s 30ms/step - loss: 0.2435 - accuracy: 0.9002 - val_loss: 0.2270 - val_accuracy: 0.9081\n",
            "-----------:: FOLD :- 5 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009963074699044228.\n",
            "7350/7350 [==============================] - 223s 30ms/step - loss: 0.2434 - accuracy: 0.9003 - val_loss: 0.2260 - val_accuracy: 0.9082\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009962078491195109.\n",
            "7350/7350 [==============================] - 225s 31ms/step - loss: 0.2433 - accuracy: 0.8998 - val_loss: 0.2249 - val_accuracy: 0.9084\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009960086166656058.\n",
            "7350/7350 [==============================] - 225s 31ms/step - loss: 0.2435 - accuracy: 0.9001 - val_loss: 0.2267 - val_accuracy: 0.9082\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009957099187976538.\n",
            "7350/7350 [==============================] - 223s 30ms/step - loss: 0.2436 - accuracy: 0.9002 - val_loss: 0.2249 - val_accuracy: 0.9087\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009953117853433479.\n",
            "7350/7350 [==============================] - 225s 31ms/step - loss: 0.2431 - accuracy: 0.9006 - val_loss: 0.2251 - val_accuracy: 0.9082\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0009948143624755993.\n",
            "7350/7350 [==============================] - 223s 30ms/step - loss: 0.2435 - accuracy: 0.9001 - val_loss: 0.2255 - val_accuracy: 0.9081\n",
            "----------------------::  TRAINING COMPLETED :- STACKED_6 ::----------------------\n",
            "\n",
            "----------------------::  TRAINING STARTED :- STACKED_7 ::----------------------\n",
            "\n",
            "-----------:: FOLD :- 1 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "7350/7350 [==============================] - 198s 24ms/step - loss: 0.2693 - accuracy: 0.9017 - val_loss: 0.3205 - val_accuracy: 0.8727\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009999000574917021.\n",
            "7350/7350 [==============================] - 168s 23ms/step - loss: 0.2279 - accuracy: 0.9071 - val_loss: 0.3230 - val_accuracy: 0.8724\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000999700106714659.\n",
            "7350/7350 [==============================] - 167s 23ms/step - loss: 0.2295 - accuracy: 0.9055 - val_loss: 0.3209 - val_accuracy: 0.8725\n",
            "-----------:: FOLD :- 2 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009997001616284251.\n",
            "7350/7350 [==============================] - 172s 23ms/step - loss: 0.2514 - accuracy: 0.8971 - val_loss: 0.2158 - val_accuracy: 0.9113\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009996002016082644.\n",
            "7350/7350 [==============================] - 172s 23ms/step - loss: 0.2510 - accuracy: 0.8972 - val_loss: 0.2151 - val_accuracy: 0.9121\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009994002808108137.\n",
            "7350/7350 [==============================] - 173s 23ms/step - loss: 0.2514 - accuracy: 0.8965 - val_loss: 0.2164 - val_accuracy: 0.9115\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009991005455957202.\n",
            "7350/7350 [==============================] - 172s 23ms/step - loss: 0.2511 - accuracy: 0.8972 - val_loss: 0.2147 - val_accuracy: 0.9120\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009987010258953365.\n",
            "7350/7350 [==============================] - 172s 23ms/step - loss: 0.2509 - accuracy: 0.8968 - val_loss: 0.2151 - val_accuracy: 0.9119\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.000998201867987191.\n",
            "7350/7350 [==============================] - 171s 23ms/step - loss: 0.2507 - accuracy: 0.8975 - val_loss: 0.2152 - val_accuracy: 0.9120\n",
            "-----------:: FOLD :- 3 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009982018964365125.\n",
            "7350/7350 [==============================] - 170s 23ms/step - loss: 0.2515 - accuracy: 0.8969 - val_loss: 0.2174 - val_accuracy: 0.9112\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009981020862278897.\n",
            "7350/7350 [==============================] - 171s 23ms/step - loss: 0.2511 - accuracy: 0.8972 - val_loss: 0.2158 - val_accuracy: 0.9115\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009979025479961076.\n",
            "7350/7350 [==============================] - 171s 23ms/step - loss: 0.2515 - accuracy: 0.8965 - val_loss: 0.2152 - val_accuracy: 0.9122\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009976033116506002.\n",
            "7350/7350 [==============================] - 171s 23ms/step - loss: 0.2512 - accuracy: 0.8970 - val_loss: 0.2170 - val_accuracy: 0.9115\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000997204407088843.\n",
            "7350/7350 [==============================] - 171s 23ms/step - loss: 0.2512 - accuracy: 0.8972 - val_loss: 0.2156 - val_accuracy: 0.9118\n",
            "-----------:: FOLD :- 4 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009972044499590993.\n",
            "7350/7350 [==============================] - 173s 24ms/step - loss: 0.2518 - accuracy: 0.8963 - val_loss: 0.2155 - val_accuracy: 0.9125\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009971047394851508.\n",
            "7350/7350 [==============================] - 174s 24ms/step - loss: 0.2514 - accuracy: 0.8965 - val_loss: 0.2151 - val_accuracy: 0.9129\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009969053009681.\n",
            "7350/7350 [==============================] - 173s 24ms/step - loss: 0.2520 - accuracy: 0.8962 - val_loss: 0.2167 - val_accuracy: 0.9128\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009966062806977948.\n",
            "7350/7350 [==============================] - 172s 23ms/step - loss: 0.2514 - accuracy: 0.8964 - val_loss: 0.2172 - val_accuracy: 0.9124\n",
            "-----------:: FOLD :- 5 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009966063080355525.\n",
            "7350/7350 [==============================] - 172s 23ms/step - loss: 0.2514 - accuracy: 0.8966 - val_loss: 0.2171 - val_accuracy: 0.9118\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009965066573698156.\n",
            "7350/7350 [==============================] - 172s 23ms/step - loss: 0.2517 - accuracy: 0.8962 - val_loss: 0.2159 - val_accuracy: 0.9127\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009963073950410605.\n",
            "7350/7350 [==============================] - 187s 25ms/step - loss: 0.2513 - accuracy: 0.8967 - val_loss: 0.2139 - val_accuracy: 0.9134\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009960085509238238.\n",
            "7350/7350 [==============================] - 190s 26ms/step - loss: 0.2515 - accuracy: 0.8966 - val_loss: 0.2147 - val_accuracy: 0.9132\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009956102712494715.\n",
            "7350/7350 [==============================] - 178s 24ms/step - loss: 0.2506 - accuracy: 0.8969 - val_loss: 0.2150 - val_accuracy: 0.9129\n",
            "----------------------::  TRAINING COMPLETED :- STACKED_7 ::----------------------\n",
            "\n",
            "----------------------::  TRAINING STARTED :- STACKED_8 ::----------------------\n",
            "\n",
            "-----------:: FOLD :- 1 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "7350/7350 [==============================] - 222s 27ms/step - loss: 0.3278 - accuracy: 0.8539 - val_loss: 0.2971 - val_accuracy: 0.8797\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009999000574917021.\n",
            "7350/7350 [==============================] - 193s 26ms/step - loss: 0.2412 - accuracy: 0.9009 - val_loss: 0.2965 - val_accuracy: 0.8799\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000999700106714659.\n",
            "7350/7350 [==============================] - 192s 26ms/step - loss: 0.2429 - accuracy: 0.9011 - val_loss: 0.2975 - val_accuracy: 0.8799\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009994003415259673.\n",
            "7350/7350 [==============================] - 197s 27ms/step - loss: 0.2413 - accuracy: 0.9016 - val_loss: 0.2964 - val_accuracy: 0.8799\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009990007918579775.\n",
            "7350/7350 [==============================] - 196s 27ms/step - loss: 0.2425 - accuracy: 0.9005 - val_loss: 0.2947 - val_accuracy: 0.8801\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0009985014876310735.\n",
            "7350/7350 [==============================] - 196s 27ms/step - loss: 0.2422 - accuracy: 0.9003 - val_loss: 0.2968 - val_accuracy: 0.8796\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0009979026914447063.\n",
            "7350/7350 [==============================] - 196s 27ms/step - loss: 0.2427 - accuracy: 0.8996 - val_loss: 0.2983 - val_accuracy: 0.8792\n",
            "-----------:: FOLD :- 2 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009979027090594172.\n",
            "7350/7350 [==============================] - 199s 27ms/step - loss: 0.2559 - accuracy: 0.8946 - val_loss: 0.2361 - val_accuracy: 0.9040\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009978029287665406.\n",
            "7350/7350 [==============================] - 201s 27ms/step - loss: 0.2560 - accuracy: 0.8945 - val_loss: 0.2369 - val_accuracy: 0.9039\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009976034204445226.\n",
            "7350/7350 [==============================] - 197s 27ms/step - loss: 0.2561 - accuracy: 0.8949 - val_loss: 0.2378 - val_accuracy: 0.9038\n",
            "-----------:: FOLD :- 3 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009976034052670002.\n",
            "7350/7350 [==============================] - 183s 25ms/step - loss: 0.2566 - accuracy: 0.8943 - val_loss: 0.2363 - val_accuracy: 0.9040\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00099750365490151.\n",
            "7350/7350 [==============================] - 184s 25ms/step - loss: 0.2563 - accuracy: 0.8942 - val_loss: 0.2353 - val_accuracy: 0.9045\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009973041765008943.\n",
            "7350/7350 [==============================] - 185s 25ms/step - loss: 0.2563 - accuracy: 0.8940 - val_loss: 0.2343 - val_accuracy: 0.9047\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009970051163549986.\n",
            "7350/7350 [==============================] - 187s 25ms/step - loss: 0.2564 - accuracy: 0.8943 - val_loss: 0.2356 - val_accuracy: 0.9041\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000996606504326401.\n",
            "7350/7350 [==============================] - 183s 25ms/step - loss: 0.2565 - accuracy: 0.8940 - val_loss: 0.2350 - val_accuracy: 0.9041\n",
            "-----------:: FOLD :- 4 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009966065408661962.\n",
            "7350/7350 [==============================] - 183s 25ms/step - loss: 0.2564 - accuracy: 0.8943 - val_loss: 0.2359 - val_accuracy: 0.9034\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009965068901771784.\n",
            "7350/7350 [==============================] - 185s 25ms/step - loss: 0.2557 - accuracy: 0.8945 - val_loss: 0.2352 - val_accuracy: 0.9034\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009963076278251472.\n",
            "7350/7350 [==============================] - 184s 25ms/step - loss: 0.2562 - accuracy: 0.8942 - val_loss: 0.2363 - val_accuracy: 0.9037\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009960087836846392.\n",
            "7350/7350 [==============================] - 182s 25ms/step - loss: 0.2560 - accuracy: 0.8943 - val_loss: 0.2360 - val_accuracy: 0.9037\n",
            "-----------:: FOLD :- 5 ::-----------\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009960087481886148.\n",
            "7350/7350 [==============================] - 185s 25ms/step - loss: 0.2559 - accuracy: 0.8942 - val_loss: 0.2359 - val_accuracy: 0.9033\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009959091572728875.\n",
            "7350/7350 [==============================] - 185s 25ms/step - loss: 0.2558 - accuracy: 0.8943 - val_loss: 0.2369 - val_accuracy: 0.9033\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000995710071074238.\n",
            "7350/7350 [==============================] - 184s 25ms/step - loss: 0.2556 - accuracy: 0.8947 - val_loss: 0.2364 - val_accuracy: 0.9035\n",
            "----------------------::  TRAINING COMPLETED :- STACKED_8 ::----------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk7m7pgDyU2S"
      },
      "source": [
        "ft_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrBbRdmKvU0C"
      },
      "source": [
        "# from keras.preprocessing.text import Tokenizer\n",
        "ft_x_val = ft_file['Tokenizer'].texts_to_sequences(val_text)\n",
        "gl100_x_val = gl100_file['Tokenizer'].texts_to_sequences(val_text)\n",
        "gl200_x_val = gl100_file['Tokenizer'].texts_to_sequences(val_text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlZypHzHvqom"
      },
      "source": [
        "\n",
        "#x_val_padded = pad_sequences(x_val, object_file[1], padding='post',truncating = 'post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jur6zaMjwsfG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NUvHWDnjH-R"
      },
      "source": [
        "dic = {}\n",
        "for i in range(len(members)):\n",
        "  model = members[i]\n",
        "  model.input._name = names[i].replace('.h5','')+'_'+model.input.name\n",
        "  #   layer._name = names[i].replace('.h5','')+layer.name\n",
        "  #   mod.append(layer.name)\n",
        "  # dic[names[i]] = mod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yllgvA9Zsism"
      },
      "source": [
        "ensemble_visible = [model.input for model in members]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq1yoCywsmYi"
      },
      "source": [
        "ensemble_visible[0]."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0VyzllAks7a"
      },
      "source": [
        "from collections import Counter\n",
        "l = []\n",
        "for layers in dic.values():\n",
        "  l.extend(layers)\n",
        "\n",
        "c = Counter(l)\n",
        "print('\\n\\n\\n',c,'\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XioXkt1Fzqo2"
      },
      "source": [
        "stacked = define_stacked_model(members)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sxyt2vY0OwA"
      },
      "source": [
        "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ0caVZ00ESb"
      },
      "source": [
        "dataset = np.hstack((in_seq1, in_seq2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS0f1QcjzWIY"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efsedzrq1cQR"
      },
      "source": [
        "# import pickle\n",
        "# # gl_200 = pickle.load(open('/content/drive/MyDrive/sarcasm models/gl_200_prep_params.pkl','rb'))\n",
        "# # gl_100 = pickle.load(open('/content/drive/MyDrive/sarcasm models/gl_100_prep_params.pkl','rb'))\n",
        "# # ft_300 = pickle.load(open('/content/drive/MyDrive/sarcasm models/ft_300_prep_params.pkl','rb'))\n",
        "# gl_200 = pickle.load(open('/content/drive/MyDrive/sentiment models/gl_200_prep_params.pkl','rb'))\n",
        "# gl_100 = pickle.load(open('/content/drive/MyDrive/sentiment models/gl_100_prep_params.pkl','rb'))\n",
        "# ft_300 = pickle.load(open('/content/drive/MyDrive/sentiment models/ft_300_prep_params.pkl','rb'))\n",
        "\n",
        "\n",
        "ft_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbAFSprW4bag"
      },
      "source": [
        "import gensim\n",
        "\n",
        "model_100 = gensim.models.Word2Vec(sentences=df['text'].values,size = 100,window=5,workers=4,min_count=1)\n",
        "model_200 = gensim.models.Word2Vec(sentences=df['text'].values,size = 200,window=5,workers=4,min_count=1)\n",
        "model_300 = gensim.models.Word2Vec(sentences=df['text'].values,size = 300,window=5,workers=4,min_count=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQbGGqzW33kf"
      },
      "source": [
        "model_100.wv.save_word2vec_format('/content/drive/MyDrive/sarcasm models/sarc_w2v_100D.txt',binary=False)\n",
        "model_200.wv.save_word2vec_format('/content/drive/MyDrive/sarcasm models/sarc_w2v_200D.txt',binary=False)\n",
        "model_300.wv.save_word2vec_format('/content/drive/MyDrive/sarcasm models/sarc_w2v_300D.txt',binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PePg3F53e8T"
      },
      "source": [
        "len(list(model_100.wv.vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyCtb_ucBHn6"
      },
      "source": [
        "!wget https://drive.google.com/u/0/open?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3tHaYgZBFaT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEWP7wlO3mJT"
      },
      "source": [
        "# SARCASM STACKING\n",
        "\n",
        "# Epoch 1/3\n",
        "# 1838/1838 [==============================] - 334s 177ms/step - loss: 0.4566 - accuracy: 0.7794\n",
        "# Epoch 2/3\n",
        "# 1838/1838 [==============================] - 325s 177ms/step - loss: 0.2568 - accuracy: 0.9022\n",
        "# Epoch 3/3\n",
        "# 1838/1838 [==============================] - 324s 176ms/step - loss: 0.2437 - accuracy: 0.9029\n",
        "# <tensorflow.python.keras.callbacks.History at 0x7f262d19dc90>\n",
        "# [18]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE7EK9Kj3lLA"
      },
      "source": [
        "# !gunzip /content/drive/MyDrive/w2v_emb/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKFQyDhkGUgp"
      },
      "source": [
        "with tf.device('/job:localhost'):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6yG8UmFwpTv"
      },
      "source": [
        "# Sentiment DATA\n",
        "\n",
        "# Epoch 1/100\n",
        "# 17250/17250 [==============================] - 371s 21ms/step - loss: 0.5395 - accuracy: 0.8170 - val_loss: 0.4415 - val_accuracy: 0.8477\n",
        "# Epoch 2/100\n",
        "# 17250/17250 [==============================] - 363s 21ms/step - loss: 0.4656 - accuracy: 0.8381 - val_loss: 0.4354 - val_accuracy: 0.8481\n",
        "# Epoch 3/100\n",
        "# 17250/17250 [==============================] - 362s 21ms/step - loss: 0.4606 - accuracy: 0.8386 - val_loss: 0.4315 - val_accuracy: 0.8486\n",
        "# Epoch 4/100\n",
        "# 17250/17250 [==============================] - 364s 21ms/step - loss: 0.4576 - accuracy: 0.8390 - val_loss: 0.4313 - val_accuracy: 0.8481\n",
        "# Epoch 5/100\n",
        "# 17250/17250 [==============================] - 362s 21ms/step - loss: 0.4579 - accuracy: 0.8382 - val_loss: 0.4288 - val_accuracy: 0.8488\n",
        "# Epoch 6/100\n",
        "# 17250/17250 [==============================] - 361s 21ms/step - loss: 0.4566 - accuracy: 0.8387 - val_loss: 0.4281 - val_accuracy: 0.8486\n",
        "# Epoch 7/100\n",
        "# 17250/17250 [==============================] - 361s 21ms/step - loss: 0.4556 - accuracy: 0.8389 - val_loss: 0.4289 - val_accuracy: 0.8485"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OSEVsIFaiQI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3cPQDuovW6p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Byl4xEsvTuL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd9Ott8fvE3H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWxlGIi1uwqf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s81Sqc5_uuxJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}