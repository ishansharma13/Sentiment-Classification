{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mark(11,12,13).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BM39SgE3wPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34dc55b4-7285-4748-cf19-609d58ab36f1"
      },
      "source": [
        "!pip install transformers==3.0.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 20.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 11.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 41.3MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrjG9MkQ461P",
        "outputId": "9ddd169f-e5a6-43d7-d2b5-864e9b9dbbab"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer,TFBertModel\n",
        "import os\n",
        "import pprint\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7NboFSC5F0J",
        "outputId": "7cec1d7f-ca0e-4aa6-a41e-f5481605ca56"
      },
      "source": [
        "import os\n",
        "import pprint # for pretty printing our device stats\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "\n",
        "    with tf.compat.v1.Session(tpu_address) as session:\n",
        "      devices = session.list_devices()\n",
        "\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.103.60.98:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 6049929223548579617),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 7536823379783746693),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2906091741893350272),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4212492621211202841),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -998447935217898149),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -1064312486843363936),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -7314498197066635037),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -1405390220126210434),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2005118012807763697),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -7171079508507978703),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 943615568984878241)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgNGy9MI5HYu",
        "outputId": "1d6becf2-4583-4f38-ecb0-adf59d206bc5"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.60.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.60.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCQWygSR5Qrt"
      },
      "source": [
        "class bertModels:\n",
        "\tdef __init__(self,path):\n",
        "\t\tdf = pd.read_csv(path)\n",
        "\t\tself.max_seq_len = 35\n",
        "\t\tbert_name = 'bert-base-uncased'\n",
        "\t\tself.tokenizer = BertTokenizer.from_pretrained(bert_name,add_special_tokens=True,max_length =self.max_seq_len,pad_to_max_length = True)\n",
        "\t\tself.train_set,self.test_set = self.prepare_data(df)\n",
        "\t\twith strategy.scope():\n",
        "\t\t\tself.bert = TFBertModel.from_pretrained(bert_name)\n",
        "\t\t\tself.bert.trainable = False\n",
        "\t\t\n",
        "\t\t\n",
        "\tdef prepare_data(self,df):\t\n",
        "\t\tdf_tr = df[df['kfold'] != 0].reset_index(drop=True)\n",
        "\t\tdf_ts = df[df['kfold'] == 0].reset_index(drop=True)\n",
        "\t\t\n",
        "\t\tbert_tr = [self.encode_data(x) for x in list(df_tr.text.values)]\n",
        "\t\tbert_ts = [self.encode_data(x) for x in list(df_ts.text.values)]\n",
        "\t\t\n",
        "\t\tencoder = LabelEncoder()\n",
        "\t\tbert_tr_lb = tf.convert_to_tensor(np_utils.to_categorical(encoder.fit_transform(df_tr.label.values)),tf.float32)\n",
        "\t\tbert_ts_lb = tf.convert_to_tensor(np_utils.to_categorical(encoder.fit_transform(df_ts.label.values)),tf.float32)\n",
        "\t\t\n",
        "\t\tx_tr = np.array(bert_tr)\n",
        "\t\tx_ts = np.array(bert_ts)\n",
        "\t\t\n",
        "\t\tx_tr_inp_ids,x_tr_att_mks = np.split(x_tr,2,axis = 1)\n",
        "\t\tx_ts_inp_ids,x_ts_att_mks = np.split(x_ts,2,axis = 1)\n",
        "\t\t\n",
        "\t\tx_tr_inp_ids = tf.convert_to_tensor(x_tr_inp_ids.squeeze(),dtype=tf.int64)\n",
        "\t\tx_tr_att_mks = tf.convert_to_tensor(x_tr_att_mks.squeeze(),dtype=tf.int64)\n",
        "\t\t\n",
        "\t\tx_ts_inp_ids = tf.convert_to_tensor(x_ts_inp_ids.squeeze(),dtype=tf.int64)\n",
        "\t\tx_ts_att_mks = tf.convert_to_tensor(x_ts_att_mks.squeeze(),dtype=tf.int64)\n",
        "\t\t\n",
        "\t\tx_tr_fin = [x_tr_inp_ids,x_tr_att_mks]\n",
        "\t\tx_ts_fin = [x_ts_inp_ids,x_ts_att_mks]\n",
        "\t\t\n",
        "\t\treturn (x_tr_fin,bert_tr_lb),(x_ts_fin,bert_ts_lb)\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\tdef encode_data(self,x):\n",
        "\t\tencoded = self.tokenizer.encode_plus(x,add_special_tokens=True,max_length =self.max_seq_len,pad_to_max_length = True,truncation=True,return_attention_mask=True,return_tensors='np')\n",
        "\t\treturn encoded['input_ids'],encoded['attention_mask']\n",
        "\t\t\n",
        "\t\t\n",
        "\t\t\n",
        "\t\n",
        "\tdef process(self,ls):\n",
        "\t\tfor name in ls:\n",
        "\t\t\this = self.compile_model(name)\n",
        "\t\t\tdf = pd.DataFrame.from_dict(his.history)\n",
        "\t\t\tdf['epoch'] = [i+1 for i in range(len(df))]\n",
        "\t\t\tdf.to_csv('/content/drive/MyDrive/Bert/sent_'+name+'.csv',index=False,header=True)\n",
        "\t\n",
        "\t\n",
        "\tdef compile_model(self,name):\n",
        "\t\twith strategy.scope():\n",
        "\t\t\tmodel = self.create_model(name)\n",
        "\t\t\tmodel.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
        "\t\t\n",
        "\t\t\n",
        "\t\tprint('\\n------------------ '+name+' ------------------\\n')\n",
        "\t\tmodel.summary()\n",
        "\t\treturn model.fit(x = self.train_set[0],y = self.train_set[1],validation_data=(self.test_set[0],self.test_set[1]),epochs=100,callbacks=[EarlyStopping()])\n",
        "\t\t\n",
        "\tdef create_model(self,name):\n",
        "\t\tinputs = tf.keras.layers.Input((self.max_seq_len,),dtype = tf.int64,name=\"input_ids\")\n",
        "\t\tmask = tf.keras.layers.Input((self.max_seq_len,),dtype = tf.int64,name=\"attention_mask\")\n",
        "\t\t\n",
        "\t\tpred = self.bert(inputs=inputs,attention_mask = mask)[0]\n",
        "\t\t\n",
        "\t\tif name == 'CONV1D GRU MK5':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'CONV1D GRU MK6':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'CONV1D MK7':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\n",
        "\t\tif name == 'CONV1D MK8':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\n",
        "\t\tif name == 'CONV1D MK9':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D MK10':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D MK11':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\n",
        "\t\tif name == 'SEP CONV1D MK12':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D MK13':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D GRU MK14':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D GRU MK15':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D GRU MK16':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D GRU MK17':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK18':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK19':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK20':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK21':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK22':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\treturn tf.keras.Model([inputs,mask],x)\n",
        "\t\t\n",
        "\t\t\n",
        "\t\t\n",
        "\t\n",
        "\t\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYz6e9o45V8s",
        "outputId": "4eb43816-66b2-4e0a-e897-a228888f342e"
      },
      "source": [
        "bert = bertModels('/content/drive/MyDrive/sentiment data/tr_sen_fin.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_tf_utils:All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVMR3l2h5XZ7",
        "outputId": "65802a30-7fe0-4950-8c31-105f7fc01557"
      },
      "source": [
        "bert.process(['SEP CONV1D MK11','SEP CONV1D MK12','SEP CONV1D MK13'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------ SEP CONV1D MK11 ------------------\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 35, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d (SeparableConv (None, 35, 32)       26912       tf_bert_model_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 17, 32)       0           separable_conv1d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_1 (SeparableCo (None, 17, 32)       1152        average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 32)           0           separable_conv1d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 32)           0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           660         dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 5)            105         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 109,511,069\n",
            "Trainable params: 28,829\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "17250/17250 [==============================] - 449s 25ms/step - loss: 0.9841 - accuracy: 0.6020 - val_loss: 0.7425 - val_accuracy: 0.7165\n",
            "Epoch 2/100\n",
            "17250/17250 [==============================] - 422s 24ms/step - loss: 0.7589 - accuracy: 0.7081 - val_loss: 0.6722 - val_accuracy: 0.7457\n",
            "Epoch 3/100\n",
            "17250/17250 [==============================] - 424s 25ms/step - loss: 0.7113 - accuracy: 0.7301 - val_loss: 0.6466 - val_accuracy: 0.7563\n",
            "Epoch 4/100\n",
            "17250/17250 [==============================] - 423s 25ms/step - loss: 0.6863 - accuracy: 0.7406 - val_loss: 0.6368 - val_accuracy: 0.7618\n",
            "Epoch 5/100\n",
            "17250/17250 [==============================] - 421s 24ms/step - loss: 0.6722 - accuracy: 0.7469 - val_loss: 0.6224 - val_accuracy: 0.7684\n",
            "Epoch 6/100\n",
            "17250/17250 [==============================] - 418s 24ms/step - loss: 0.6648 - accuracy: 0.7506 - val_loss: 0.6276 - val_accuracy: 0.7666\n",
            "\n",
            "------------------ SEP CONV1D MK12 ------------------\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 35, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_2 (SeparableCo (None, 35, 32)       26912       tf_bert_model_1[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_1 (AveragePoo (None, 17, 32)       0           separable_conv1d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_3 (SeparableCo (None, 17, 32)       1152        average_pooling1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_2 (AveragePoo (None, 8, 32)        0           separable_conv1d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 256)          0           average_pooling1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 256)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          131584      dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 128)          65664       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 32)           4128        dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 5)            165         dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,711,845\n",
            "Trainable params: 229,605\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "17250/17250 [==============================] - 458s 26ms/step - loss: 0.9530 - accuracy: 0.6154 - val_loss: 0.7494 - val_accuracy: 0.7105\n",
            "Epoch 2/100\n",
            "17250/17250 [==============================] - 436s 25ms/step - loss: 0.7562 - accuracy: 0.7107 - val_loss: 0.6906 - val_accuracy: 0.7422\n",
            "Epoch 3/100\n",
            "17250/17250 [==============================] - 438s 25ms/step - loss: 0.7045 - accuracy: 0.7344 - val_loss: 0.6455 - val_accuracy: 0.7598\n",
            "Epoch 4/100\n",
            "17250/17250 [==============================] - 433s 25ms/step - loss: 0.6817 - accuracy: 0.7434 - val_loss: 0.6437 - val_accuracy: 0.7588\n",
            "Epoch 5/100\n",
            "17250/17250 [==============================] - 437s 25ms/step - loss: 0.6713 - accuracy: 0.7475 - val_loss: 0.6283 - val_accuracy: 0.7660\n",
            "Epoch 6/100\n",
            "17250/17250 [==============================] - 435s 25ms/step - loss: 0.6634 - accuracy: 0.7511 - val_loss: 0.6333 - val_accuracy: 0.7690\n",
            "\n",
            "------------------ SEP CONV1D MK13 ------------------\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 35, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_4 (SeparableCo (None, 35, 32)       26912       tf_bert_model_1[2][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 17, 32)       0           separable_conv1d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_5 (SeparableCo (None, 17, 32)       1152        max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 8, 32)        0           separable_conv1d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 256)          0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 256)          0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 512)          131584      dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 128)          65664       dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 32)           4128        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 5)            165         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,711,845\n",
            "Trainable params: 229,605\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "17250/17250 [==============================] - 465s 26ms/step - loss: 0.9479 - accuracy: 0.6180 - val_loss: 0.7231 - val_accuracy: 0.7211\n",
            "Epoch 2/100\n",
            "17250/17250 [==============================] - 442s 26ms/step - loss: 0.7363 - accuracy: 0.7207 - val_loss: 0.6679 - val_accuracy: 0.7477\n",
            "Epoch 3/100\n",
            "17250/17250 [==============================] - 440s 26ms/step - loss: 0.6997 - accuracy: 0.7353 - val_loss: 0.6697 - val_accuracy: 0.7514\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}