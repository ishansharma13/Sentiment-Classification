{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Mark(17,18,19).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbeFIE8e636e",
        "outputId": "da0bbb11-7268-449e-bddb-47e9a230747a"
      },
      "source": [
        "!pip install transformers==3.0.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 33.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdGQ3Ncq7NPl",
        "outputId": "dddeeb60-06f0-4f6e-dbb3-811f59cbe2fc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer,TFBertModel\n",
        "import os\n",
        "import pprint\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnJzEHgK7Qhd",
        "outputId": "5129a0dd-c927-49ed-ba20-737c1b794b9a"
      },
      "source": [
        "import os\n",
        "import pprint # for pretty printing our device stats\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "\n",
        "    with tf.compat.v1.Session(tpu_address) as session:\n",
        "      devices = session.list_devices()\n",
        "\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.38.39.106:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 8493604122835769228),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -2241762228598576607),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5315941997097594361),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -4465388141405626486),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 9199510589349034322),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -8218022659760275660),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6187970629837156610),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5688184025550518019),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2108073862680300909),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -6291608652557164362),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -7313291719622891130)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCS_-bLU7Tmw",
        "outputId": "b331519b-66de-4a67-9bfc-9528131bc422"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.39.106:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.38.39.106:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdFY2JaA7XTR"
      },
      "source": [
        "class bertModels:\n",
        "\tdef __init__(self,path):\n",
        "\t\tdf = pd.read_csv(path)\n",
        "\t\tself.max_seq_len = 35\n",
        "\t\tbert_name = 'bert-base-uncased'\n",
        "\t\tself.tokenizer = BertTokenizer.from_pretrained(bert_name,add_special_tokens=True,max_length =self.max_seq_len,pad_to_max_length = True)\n",
        "\t\tself.train_set,self.test_set = self.prepare_data(df)\n",
        "\t\twith strategy.scope():\n",
        "\t\t\tself.bert = TFBertModel.from_pretrained(bert_name)\n",
        "\t\t\tself.bert.trainable = False\n",
        "\t\t\n",
        "\t\t\n",
        "\tdef prepare_data(self,df):\t\n",
        "\t\tdf_tr = df[df['kfold'] != 0].reset_index(drop=True)\n",
        "\t\tdf_ts = df[df['kfold'] == 0].reset_index(drop=True)\n",
        "\t\t\n",
        "\t\tbert_tr = [self.encode_data(x) for x in list(df_tr.text.values)]\n",
        "\t\tbert_ts = [self.encode_data(x) for x in list(df_ts.text.values)]\n",
        "\t\t\n",
        "\t\tencoder = LabelEncoder()\n",
        "\t\tbert_tr_lb = tf.convert_to_tensor(np_utils.to_categorical(encoder.fit_transform(df_tr.label.values)),tf.float32)\n",
        "\t\tbert_ts_lb = tf.convert_to_tensor(np_utils.to_categorical(encoder.fit_transform(df_ts.label.values)),tf.float32)\n",
        "\t\t\n",
        "\t\tx_tr = np.array(bert_tr)\n",
        "\t\tx_ts = np.array(bert_ts)\n",
        "\t\t\n",
        "\t\tx_tr_inp_ids,x_tr_att_mks = np.split(x_tr,2,axis = 1)\n",
        "\t\tx_ts_inp_ids,x_ts_att_mks = np.split(x_ts,2,axis = 1)\n",
        "\t\t\n",
        "\t\tx_tr_inp_ids = tf.convert_to_tensor(x_tr_inp_ids.squeeze(),dtype=tf.int64)\n",
        "\t\tx_tr_att_mks = tf.convert_to_tensor(x_tr_att_mks.squeeze(),dtype=tf.int64)\n",
        "\t\t\n",
        "\t\tx_ts_inp_ids = tf.convert_to_tensor(x_ts_inp_ids.squeeze(),dtype=tf.int64)\n",
        "\t\tx_ts_att_mks = tf.convert_to_tensor(x_ts_att_mks.squeeze(),dtype=tf.int64)\n",
        "\t\t\n",
        "\t\tx_tr_fin = [x_tr_inp_ids,x_tr_att_mks]\n",
        "\t\tx_ts_fin = [x_ts_inp_ids,x_ts_att_mks]\n",
        "\t\t\n",
        "\t\treturn (x_tr_fin,bert_tr_lb),(x_ts_fin,bert_ts_lb)\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\tdef encode_data(self,x):\n",
        "\t\tencoded = self.tokenizer.encode_plus(x,add_special_tokens=True,max_length =self.max_seq_len,pad_to_max_length = True,truncation=True,return_attention_mask=True,return_tensors='np')\n",
        "\t\treturn encoded['input_ids'],encoded['attention_mask']\n",
        "\t\t\n",
        "\t\t\n",
        "\t\t\n",
        "\t\n",
        "\tdef process(self,ls):\n",
        "\t\tfor name in ls:\n",
        "\t\t\this = self.compile_model(name)\n",
        "\t\t\tdf = pd.DataFrame.from_dict(his.history)\n",
        "\t\t\tdf['epoch'] = [i+1 for i in range(len(df))]\n",
        "\t\t\tdf.to_csv('/content/drive/MyDrive/Bert/sent_'+name+'.csv',index=False,header=True)\n",
        "\t\n",
        "\t\n",
        "\tdef compile_model(self,name):\n",
        "\t\twith strategy.scope():\n",
        "\t\t\tmodel = self.create_model(name)\n",
        "\t\t\tmodel.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
        "\t\t\n",
        "\t\t\n",
        "\t\tprint('\\n------------------ '+name+' ------------------\\n')\n",
        "\t\tmodel.summary()\n",
        "\t\treturn model.fit(x = self.train_set[0],y = self.train_set[1],validation_data=(self.test_set[0],self.test_set[1]),epochs=100,callbacks=[EarlyStopping()])\n",
        "\t\t\n",
        "\tdef create_model(self,name):\n",
        "\t\tinputs = tf.keras.layers.Input((self.max_seq_len,),dtype = tf.int64,name=\"input_ids\")\n",
        "\t\tmask = tf.keras.layers.Input((self.max_seq_len,),dtype = tf.int64,name=\"attention_mask\")\n",
        "\t\t\n",
        "\t\tpred = self.bert(inputs=inputs,attention_mask = mask)[0]\n",
        "\t\t\n",
        "\t\tif name == 'CONV1D GRU MK5':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'CONV1D GRU MK6':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'CONV1D MK7':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\n",
        "\t\tif name == 'CONV1D MK8':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\n",
        "\t\tif name == 'CONV1D MK9':\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D MK10':\n",
        "\t\t\tx = tf.keras.layers.SeperableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D MK11':\n",
        "\t\t\tx = tf.keras.layers.SeperableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\n",
        "\t\tif name == 'SEP CONV1D MK12':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D MK13':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D GRU MK14':\n",
        "\t\t\tx = tf.keras.layers.SeperableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D GRU MK15':\n",
        "\t\t\tx = tf.keras.layers.SeperableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D GRU MK16':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'SEP CONV1D GRU MK17':\n",
        "\t\t\tx = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK18':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "\t\t\tx = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK19':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "\t\t\tx = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK20':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "\t\t\tx = tf.keras.layers.AveragePooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK21':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "\t\t\tx = tf.keras.layers.MaxPooling1D()(x)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\tif name == 'BiGRU MK22':\n",
        "\t\t\tx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "\t\t\tx = tf.keras.layers.Flatten()(x)\n",
        "\t\t\tx = tf.keras.layers.Dropout(0.2)(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "\t\t\tx = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\t\t\t\n",
        "\t\treturn tf.keras.Model([inputs,mask],x)\n",
        "\t\t\n",
        "\t\t\n",
        "\t\t\n",
        "\t\n",
        "\t\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AJV4-umQ7ayG",
        "outputId": "cf02395a-f7df-4b00-d77d-b5f5d622f8f8"
      },
      "source": [
        "bert = bertModels('/content/drive/MyDrive/sentiment data/tr_sen_fin.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_tf_utils:All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkWea9zj7eGw"
      },
      "source": [
        "bert.process(['SEP CONV1D GRU MK17','BiGRU MK18','BiGRU MK19'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}