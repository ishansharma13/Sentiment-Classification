{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mean_sent",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhDFvHCiysdR",
        "outputId": "0e243678-b499-4c85-f580-60a6e5e1a4d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sY_GERZzDru"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbgfYOr6zEbc",
        "outputId": "2e8438b8-6f63-43df-af91-cfbd9cbe35b7"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 72kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 19.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=bacb46fc69af5e039d06b21c25bed37513177dfad000f2886a337fe3986ad5b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ecRV-czgex"
      },
      "source": [
        "from pyspark.sql import SparkSession as ss\n",
        "spark = ss.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFQJR1aI0a29"
      },
      "source": [
        "# os.chdir('Annotated')\n",
        "files = [file for file in os.listdir() if not file.startswith('.')]\n",
        "files.remove('sentiment140')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYqeFQDszVxZ",
        "outputId": "87c69d94-6ef3-4975-9bc0-f7b34c2d874f"
      },
      "source": [
        "files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['total_combined_text_and_ids_preprocessed_upd_res',\n",
              " 'SMILE_Twitter_Emotion_dataset_cleaned_preprocessed',\n",
              " 'Brands_and_Product_Emotions_cleaned.csv_preprocessed',\n",
              " 'The_Valence_and_Arousal_Facebook_Posts_cleaned_preprocessed',\n",
              " 'Affect_data_cleaned.csv_preprocessed',\n",
              " 'Sentiment_Labelled_Sentences_Data_Set_cleaned_preprocessed',\n",
              " 'Sentiment_Analysis_in_Text_cleaned.csv_preprocessed',\n",
              " 'Sentiment_Emotion_Mining_Toolkit_(EMTk)_cleaned_preprocessed',\n",
              " 'Primary_Emotions_of_Statements_cleaned_preprocessed',\n",
              " 'WASSA_2017_Shared_Task_on_Emotion_Intensity_cleaned.csv_preprocessed',\n",
              " 'IMDB_cleaned.csv_preprocessed',\n",
              " 'sentiment140-combined']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI2QWzCs19sC"
      },
      "source": [
        "df = spark.read.csv(\"/content/drive/MyDrive/Annotated/EmoBank_cleaned.csv_preprocessed\",header = True, multiLine=True,inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LC-IB6g2jd3"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType,FloatType\n",
        "class cal_mean_sentiment:\n",
        "  def __init__(self):\n",
        "    # self.path_read = '/content/drive/MyDrive/Annotated/'\n",
        "    self.path = '/content/drive/MyDrive/Annotated/mean_sent_lex/'\n",
        "    \n",
        "  @staticmethod\n",
        "  @udf(returnType = StringType())\n",
        "  def classify(score):\n",
        "      if score>0.5:\n",
        "          return 'VPos'\n",
        "      if score>0 and score<=0.5:\n",
        "          return 'Pos'\n",
        "      if score<0 and score>=-0.5:\n",
        "          return 'Neg'\n",
        "      if score<-0.5:\n",
        "          return 'VNeg'\n",
        "      return 'Neu'\n",
        "\n",
        "  def process(self,f):\n",
        "    self.df = spark.read.csv(self.path+f,header = True,multiLine=True,inferSchema=True)\n",
        "    self.df = self.df.dropna()\n",
        "    # self.df = self.df.withColumn(\"mean_sent_score\", (col(\"vader_score\")+col(\"blob_score\")+col(\"afinn_score\"))/3)\n",
        "    # unlist = udf(lambda x: float(list(x)[0]), FloatType())\n",
        "    # self.df = self.df.withColumn('mean_sent_score_f',unlist('mean_sent_score'))\n",
        "    # self.df = self.df.withColumnRenamed('mean_sent_score_f','mean_sent_score')\n",
        "    self.df = self.df.withColumn(\"final_sent_class\", cal_mean_sentiment.classify(\"mean_sent_score\"))\n",
        "    print(\"SAVING -- \"+f)\n",
        "    self.df.write.mode(\"overwrite\").option(\"header\",\"true\").csv(self.path+'final_sent_class/'+f)\n",
        "    print(\"SAVED -- \"+f)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRxlRwiHzgY_",
        "outputId": "d405845f-d1b8-4376-b52f-0f45cce253d1"
      },
      "source": [
        "c = cal_mean_sentiment()\n",
        "c.process(files[11])\n",
        "# path = '/content/drive/MyDrive/Annotated/mean_sent_lex/'\n",
        "# df = spark.read.csv(path+files[11],header = True, multiLine=True,inferSchema=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SAVING -- sentiment140-combined\n",
            "SAVED -- sentiment140-combined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWmQ1Xt46dOE",
        "outputId": "3a60600f-7def-437a-e3f2-0bf3be95bc3c"
      },
      "source": [
        "df.dropna().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1568971"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm-dylPrs7A2"
      },
      "source": [
        "from functools import reduce\n",
        "from pyspark.sql import DataFrame\n",
        "\n",
        "def unionAll(*dfs):\n",
        "    return reduce(DataFrame.unionAll, dfs)\n",
        "\n",
        "# unionAll(df_summerfruits, df_fruits, df_dryfruits).distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx8tWcgkt97D"
      },
      "source": [
        "df0 = spark.read.csv(\"/content/drive/MyDrive/Annotated/sentiment140-combined\",header = True, multiLine=True,inferSchema=True)\n",
        "# df1 = spark.read.csv(\"/content/drive/MyDrive/Annotated/sentiment140/part-1\",header = True, escape=\"\\\"\",multiLine=True,inferSchema=True)\n",
        "# df2 = spark.read.csv(\"/content/drive/MyDrive/Annotated/sentiment140/part-2\",header = True, escape=\"\\\"\",multiLine=True,inferSchema=True)\n",
        "# df3 = spark.read.csv(\"/content/drive/MyDrive/Annotated/sentiment140/part-3\",header = True, escape=\"\\\"\",multiLine=True,inferSchema=True)\n",
        "# df4 = spark.read.csv(\"/content/drive/MyDrive/Annotated/sentiment140/part-4\",header = True, escape=\"\\\"\",multiLine=True,inferSchema=True)\n",
        "# df5 = spark.read.csv(\"/content/drive/MyDrive/Annotated/sentiment140/part-5\",header = True, escape=\"\\\"\",multiLine=True,inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmFqZkmVvKto"
      },
      "source": [
        "comb_df = unionAll(df0,df1,df2,df3,df4,df5).distinct()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq_nvno4vTQ-"
      },
      "source": [
        "comb_df = comb_df.drop_duplicates().dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ekIUGzjwAQe",
        "outputId": "124e770d-6ce5-46cd-9979-3029163e0cfa"
      },
      "source": [
        "print(df0.count())\n",
        "# print(df1.count())\n",
        "# print(df2.count())\n",
        "# print(df3.count())\n",
        "# print(df4.count())\n",
        "# print(df5.count())\n",
        "# print(comb_df.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1569317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGaStlfSwE6i"
      },
      "source": [
        "comb_df.write.mode(\"overwrite\").option(\"header\",\"true\").csv('/content/drive/MyDrive/Annotated/sentiment140-combined')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}