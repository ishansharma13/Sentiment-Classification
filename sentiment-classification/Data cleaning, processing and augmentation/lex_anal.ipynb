{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lex_anal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk4qEjaWJDkQ",
        "outputId": "c4f4946e-b379-4fee-fac2-6a4e82ae7f1a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MJycXX-Kpfz",
        "outputId": "a357bc81-16a9-48de-d732-aab7b87df9cc"
      },
      "source": [
        "!pip install afinn\n",
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting afinn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-cp37-none-any.whl size=53451 sha256=4162b4bca95b37c7d33b8184a9054af7901dce78dcba202c68c9fc4680b28925\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 70kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 18.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=2f058ed31a67cff5ce1d49896e555076f7d8bcaa2fce8c57e86f8f92ea9d03de\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIh5zXIhKsHz",
        "outputId": "6f206294-288a-4835-dfbe-a5404482e0b8"
      },
      "source": [
        "from pyspark.sql import SparkSession as ss\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.ml.feature import MaxAbsScaler\n",
        "# from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.types import FloatType,StringType\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from afinn import Afinn\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "spark = ss.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXB1FrlwhZs0"
      },
      "source": [
        "class lex_anal:\n",
        "  def __init__(self):\n",
        "      # self.f = file\n",
        "      self.path_read = '/content/drive/My Drive/Preprocessed/New/'\n",
        "      self.path_write = '/content/drive/My Drive/LATEST'\n",
        "      # self.df = spark.read.option(\"header\",\"true\").csv(self.path_read+self.f,inferSchema = True)\n",
        "\n",
        "  \n",
        "  def process(self,df):\n",
        "      df = self.process_score(df)\n",
        "      df = self.scale(df)\n",
        "      df = self.process_class(df)\n",
        "      self.save(df)\n",
        "  \n",
        "  \n",
        "  @staticmethod\n",
        "  @udf(returnType=FloatType())\n",
        "  def vader_pol(text):\n",
        "      vader = SentimentIntensityAnalyzer()\n",
        "      return dict(vader.polarity_scores(text))['compound']\n",
        "\n",
        "  @staticmethod\n",
        "  @udf(returnType=FloatType())\n",
        "  def afinn_pol(text):\n",
        "      af = Afinn()\n",
        "      return af.score(text)\n",
        "\n",
        "  @staticmethod\n",
        "  @udf(returnType = FloatType())\n",
        "  def blob_pol(text):\n",
        "      return TextBlob(text).polarity\n",
        "\n",
        "  def process_score(self,df):\n",
        "      df = df.withColumn('vader_score',lex_anal.vader_pol('pre_text_vader'))\n",
        "      df = df.withColumn('afinn_score',lex_anal.afinn_pol('pre_text_all_upd'))\n",
        "      df = df.withColumn('blob_score',lex_anal.blob_pol('pre_text_all_upd'))\n",
        "      return df\n",
        "\n",
        "  def process_class(self,df):\n",
        "      df = df.withColumn('vader_class',lex_anal.classify('vader_score'))\n",
        "      df = df.withColumn('afinn_class',lex_anal.classify('afinn_score'))\n",
        "      df = df.withColumn('blob_class',lex_anal.classify('blob_score'))\n",
        "      return df\n",
        "  \n",
        "  def save(self,df):\n",
        "      df.write.mode(\"overwrite\").option(\"header\",\"true\").csv(self.path_write+'covid_dataset')\n",
        "\n",
        "\n",
        "  def scale(self,df):\n",
        "      columns_to_scale = [\"afinn_score\"]\n",
        "      assemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in columns_to_scale]\n",
        "      scalers = [MaxAbsScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in columns_to_scale]\n",
        "      pipeline = Pipeline(stages=assemblers + scalers)\n",
        "      scalerModel = pipeline.fit(df)\n",
        "      scaledData = scalerModel.transform(df)\n",
        "    # scaledData = scaledData.drop('afinn_score_vec')\n",
        "      unlist = udf(lambda x: float(list(x)[0]), FloatType())\n",
        "      scaledData = scaledData.withColumn('afinn_score_scaled_f',unlist('afinn_score_scaled'))\n",
        "      scaledData = scaledData.drop('afinn_score_scaled','afinn_score_vec','afinn_score')\n",
        "      scaledData = scaledData.withColumnRenamed('afinn_score_scaled_f','afinn_score')\n",
        "      df = scaledData\n",
        "      return df\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  @udf(returnType = StringType())\n",
        "  def classify(score):\n",
        "      if score>0.5:\n",
        "          return 'VPos'\n",
        "      if score>0 and score<=0.5:\n",
        "          return 'Pos'\n",
        "      if score<0 and score>=-0.5:\n",
        "          return 'Neg'\n",
        "      if score<-0.5:\n",
        "          return 'VNeg'\n",
        "      return 'Neu'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B_IEECYlVlB"
      },
      "source": [
        "l = lex_anal()\n",
        "l.process(df_sp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf3GPuEOezfQ"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/Preprocessed/New/total_combined_text_and_ids_preprocessed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu5TOCW0RQFU",
        "outputId": "aa15419b-7744-449d-f208-3c1ae348beca"
      },
      "source": [
        "df_sp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[text: string, pre_text_vader: string, pre_text_all_upd: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoMrjeTHe07L"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "mySchema = StructType([ StructField(\"text\", StringType(), True),StructField(\"pre_text_vader\", StringType(), True),StructField(\"pre_text_all_upd\", StringType(), True)])\n",
        "df_sp = spark.createDataFrame(df,schema=mySchema)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhqPngrDk8BD"
      },
      "source": [
        "df_sp.write.option(\"header\",\"true\").csv('/content/drive/My Drive/Preprocessed/New/total_combined_text_and_ids_preprocessed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvkemOO1k9EB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQr2-BN-LCJ7"
      },
      "source": [
        "spark = ss.builder.getOrCreate()\n",
        "df = spark.read.option(\"header\",\"true\").csv('/content/drive/My Drive/Preprocessed/New/lex_sen/Sentiment_Labelled_Sentences_Data_Set_cleaned_preprocessed',inferSchema = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otD9-VQalvxi"
      },
      "source": [
        "import pandas as pd\n",
        "df2 = pd.read_csv('/content/drive/My Drive/Preprocessed/New/lex_sen/Sentiment_Labelled_Sentences_Data_Set_cleaned_preprocessed/part-00000-0b519276-7e50-48c0-b6f1-d16eb8b369cb-c000.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lSggFTTickq"
      },
      "source": [
        "df1 = df.select(\"vader_score\",\"afinn_score\",\"blob_score\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj3z5MmUizL2"
      },
      "source": [
        "unlist = udf(lambda x: float(list(x)[0]), FloatType())\n",
        "df1 = df1.withColumn(\"vader_score\",unlist(\"vader_score\"))\n",
        "df1 = df1.withColumn(\"afinn_score\",unlist(\"afinn_score\"))\n",
        "df1 = df1.withColumn(\"blob_score\",unlist(\"blob_score\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g79_ov2gjNbC"
      },
      "source": [
        "columns_to_scale = [\"afinn_score\"]\n",
        "assemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in columns_to_scale]\n",
        "scalers = [MaxAbsScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in columns_to_scale]\n",
        "pipeline = Pipeline(stages=assemblers + scalers)\n",
        "scalerModel = pipeline.fit(df)\n",
        "scaledData = scalerModel.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBnpLe-7i2K4",
        "outputId": "4666fb74-c533-4c89-f497-1b9aa0b8ed09"
      },
      "source": [
        "scaledData.drop('vader_score','vader_class')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[text: string, pre_text_vader: string, pre_text_all_upd: string, afinn_score: double, afinn_class: string, blob_score: double, blob_class: string, afinn_score_vec: vector, afinn_score_scaled: vector]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vPyGsJNYkU2"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV3bh1vUaHGH"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Preprocessed/New/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-lIF11-aOd-"
      },
      "source": [
        "files = [file for file in os.listdir() if file.endswith('preprocessed')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuSsdPz7bHVO",
        "outputId": "56543055-f97e-4aea-aa30-cf2ba392e08f"
      },
      "source": [
        "files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sentiment140_cleaned_csv_preprocessed',\n",
              " 'Sentiment_Analysis_in_Text_cleaned.csv_preprocessed',\n",
              " 'IMDB_cleaned.csv_preprocessed',\n",
              " 'The_Valence_and_Arousal_Facebook_Posts_cleaned_preprocessed',\n",
              " 'Primary_Emotions_of_Statements_cleaned_preprocessed',\n",
              " 'Sentiment_Emotion_Mining_Toolkit_(EMTk)_cleaned_preprocessed',\n",
              " 'Brands_and_Product_Emotions_cleaned.csv_preprocessed',\n",
              " 'WASSA_2017_Shared_Task_on_Emotion_Intensity_cleaned.csv_preprocessed',\n",
              " 'EmoBank_cleaned.csv_preprocessed',\n",
              " 'Sentiment_Labelled_Sentences_Data_Set_cleaned_preprocessed',\n",
              " 'SMILE_Twitter_Emotion_dataset_cleaned_preprocessed',\n",
              " 'Affect_data_cleaned.csv_preprocessed',\n",
              " 'total_combined_text_and_ids_preprocessed']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZycgoEtbIdG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaubSox1aJS1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM6ymp2ji0LU"
      },
      "source": [
        "s = '-0.5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpg60Tj2lh_R"
      },
      "source": [
        "f = float(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kro65MMDixRz",
        "outputId": "5ba98467-7195-4773-ded6-aef9c732d9e1"
      },
      "source": [
        "f"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML8tzwDNlkkF",
        "outputId": "bd641b55-e621-4dd7-98c5-ebed57e846fe"
      },
      "source": [
        "max(df2['afinn_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWNVsAjRnGIS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfAn8pHuilWJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}