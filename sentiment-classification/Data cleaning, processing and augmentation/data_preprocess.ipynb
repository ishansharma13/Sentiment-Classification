{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocess.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8jCZ4UfYqEK"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MyUPkY8Z7oF",
        "outputId": "7bbb7e4d-ead0-4172-a873-793745512b5c"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNjnhkdiaEAw"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHXe9rCXae5V",
        "outputId": "30458911-ebe1-400e-c44b-24c7528d08a8"
      },
      "source": [
        "%cd gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/MyDrive'\n",
            "/content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj44zPPlbjiL",
        "outputId": "25a693b4-0543-429a-ce3e-5999a553ee6f"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mMyDrive\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p5gkrkRbljJ",
        "outputId": "d309e745-58d7-4c52-cafb-22ba7072ccd6"
      },
      "source": [
        "%cd MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE1bnE5DbqlA",
        "outputId": "0def190f-c5f8-48c9-ff1e-81ac6fbb2963"
      },
      "source": [
        "%cd NLP"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keCdPcYlbtJ9",
        "outputId": "868fd7a5-f61b-4d10-cb92-e14446fff733"
      },
      "source": [
        "%cd Datasets/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/NLP/Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oNa9X8Cb7eB",
        "outputId": "7c06d51b-8e81-40f7-e151-e963306eab9b"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'archive (10).zip'   \u001b[0m\u001b[01;34mmod_base.parquet\u001b[0m/   sentiment140.csv   sentiment_data.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHRy5Ii7b9HG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4nT1ZLMab3Iw",
        "outputId": "bada39d4-148e-4f03-8588-0dda83a6839f"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Definitly a family favorite!  We have been goi...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Yelp_dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Extremely bland and watery. I decided to try i...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>Yelp_dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@so_jentastic Thanks girl  i plan on making th...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Sentiment140 dataset with 1.6 million tweets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The owners were super nice and extremely helpf...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Yelp_dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>First off I have nothing good to say about thi...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Yelp_dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12404947</th>\n",
              "      <td>Worst Pharmacy I have dealt with.  The script ...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Yelp_dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12404948</th>\n",
              "      <td>I'm from Chicago...so planning a wedding in ve...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Yelp_dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12404949</th>\n",
              "      <td>A testament: This was a powerful testament to...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Amazon Reviews for Sentiment Analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12404950</th>\n",
              "      <td>WOW! What can I say. He's outdone himself agai...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Yelp_dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12404951</th>\n",
              "      <td>This is probably my favorite breakfast place i...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Yelp_dataset</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12404952 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       text  ...                                        Source\n",
              "0         Definitly a family favorite!  We have been goi...  ...                                  Yelp_dataset\n",
              "1         Extremely bland and watery. I decided to try i...  ...                                  Yelp_dataset\n",
              "2         @so_jentastic Thanks girl  i plan on making th...  ...  Sentiment140 dataset with 1.6 million tweets\n",
              "3         The owners were super nice and extremely helpf...  ...                                  Yelp_dataset\n",
              "4         First off I have nothing good to say about thi...  ...                                  Yelp_dataset\n",
              "...                                                     ...  ...                                           ...\n",
              "12404947  Worst Pharmacy I have dealt with.  The script ...  ...                                  Yelp_dataset\n",
              "12404948  I'm from Chicago...so planning a wedding in ve...  ...                                  Yelp_dataset\n",
              "12404949   A testament: This was a powerful testament to...  ...         Amazon Reviews for Sentiment Analysis\n",
              "12404950  WOW! What can I say. He's outdone himself agai...  ...                                  Yelp_dataset\n",
              "12404951  This is probably my favorite breakfast place i...  ...                                  Yelp_dataset\n",
              "\n",
              "[12404952 rows x 3 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lswCI1pRa1-B"
      },
      "source": [
        "with open('sentiment_data.pkl','rb') as f:\n",
        "  data = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7xeosALbChS"
      },
      "source": [
        "data.drop('Training_evaluation_split',axis = 1,inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_cnb1kCcq2n"
      },
      "source": [
        "l1 = data['Source'].unique().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LKj_5uXdJk4"
      },
      "source": [
        "yelp = data[data['Source'] == 'Yelp_dataset']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpz8bh60dHSh"
      },
      "source": [
        "amazon_reviews = data[data['Source'] == 'Amazon Reviews for Sentiment Analysis']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKIEaqqZdDmr"
      },
      "source": [
        "emtk = data[data['Source'] == 'Sentiment/Emotion Mining Toolkit (EMTk)']\n",
        "brands_prod = data[data['Source'] == 'Brands and Product Emotions']\n",
        "sent_labelled = data[data['Source'] == 'Sentiment Labelled Sentences Data Set']\n",
        "sent_anal = data[data['Source'] == 'Sentiment Analysis in Text']\n",
        "imdb = data[data['Source'] == 'IMDB']\n",
        "prim_emo = data[data['Source'] == 'Primary Emotions of Statements']\n",
        "smile_twitter = data[data['Source'] == 'SMILE Twitter Emotion dataset']\n",
        "emobank = data[data['Source'] == 'EmoBank']\n",
        "sst_2 = data[data['Source'] == 'SST_2']\n",
        "affect = data[data['Source'] == 'Affect Data']\n",
        "sst_5 = data[data['Source'] == 'SST_5']\n",
        "wassa = data[data['Source'] == 'WASSA-2017 Shared Task on Emotion Intensity']\n",
        "fb_pts = data[data['Source'] == 'The Valence and Arousal Facebook Posts']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Y38sr-cull"
      },
      "source": [
        "l = [yelp,amazon_reviews,emtk,brands_prod,sent_labelled,sent_anal,imdb,prim_emo,smile_twitter,emobank,sst_2,affect,sst_5,wassa,fb_pts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig0V_UfroKH7"
      },
      "source": [
        "yelp.to_csv('/content/gdrive/My Drive/NLP/Datasets/Yelp_dataset.csv')\n",
        "amazon_reviews.to_csv('/content/gdrive/My Drive/NLP/Datasets/Amazon_Reviews_for_Sentiment_Analysis.csv')\n",
        "emtk.to_csv('/content/gdrive/My Drive/NLP/Datasets/Sentiment_Emotion_Mining_Toolkit_(EMTk).csv')\n",
        "brands_prod.to_csv('/content/gdrive/My Drive/NLP/Datasets/Brands_and_Product_Emotions.csv')\n",
        "sent_labelled.to_csv('/content/gdrive/My Drive/NLP/Datasets/Sentiment_Labelled_Sentences_Data_Set.csv')\n",
        "sent_anal.to_csv('/content/gdrive/My Drive/NLP/Datasets/Sentiment_Analysis_in_Text.csv')\n",
        "imdb.to_csv('/content/gdrive/My Drive/NLP/Datasets/IMDB.csv')\n",
        "prim_emo.to_csv('/content/gdrive/My Drive/NLP/Datasets/Primary_Emotions_of_Statements.csv')\n",
        "smile_twitter.to_csv('/content/gdrive/My Drive/NLP/Datasets/SMILE_Twitter_Emotion_dataset.csv')\n",
        "emobank.to_csv('/content/gdrive/My Drive/NLP/Datasets/EmoBank.csv')\n",
        "sst_2.to_csv('/content/gdrive/My Drive/NLP/Datasets/SST_2.csv')\n",
        "affect.to_csv('/content/gdrive/My Drive/NLP/Datasets/Affect_Data.csv')\n",
        "sst_5.to_csv('/content/gdrive/My Drive/NLP/Datasets/SST_5.csv')\n",
        "wassa.to_csv('/content/gdrive/My Drive/NLP/Datasets/WASSA_2017_Shared_Task_on_Emotion_Intensity.csv')\n",
        "fb_pts.to_csv('/content/gdrive/My Drive/NLP/Datasets/The_Valence_and_Arousal_Facebook_Posts.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GudwhxZpoadz",
        "outputId": "9fcd0a30-78e0-4a3c-c3ba-115ce9f79982"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/67/5158f846202d7f012d1c9ca21c3549a58fd3c6707ae8ee823adcaca6473c/pyspark-3.0.2.tar.gz (204.8MB)\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 54kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186687 sha256=2a5efd9a14d2dea905769517a07e403f88d0009cffe0bafe54d1e5000651561c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/09/da/c1f2859bcc86375dc972c5b6af4881b3603269bcc4c9be5d16\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgcN1dL3uDJw"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46xh5E1_u7S1"
      },
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nt-ncP7IvJKm"
      },
      "source": [
        "data.to_csv('/content/gdrive/My Drive/NLP/Datasets/combined_ds.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}