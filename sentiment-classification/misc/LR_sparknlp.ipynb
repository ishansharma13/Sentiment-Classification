{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LR sparknlp.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmUFXFsFiYV6",
        "outputId": "e294f165-3f99-4f83-a53d-8c8b544d9b34"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHIJ01vxi0tS",
        "outputId": "abbef79b-1acf-485a-807b-8140640e8ccf"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-17 15:14:52--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.26\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.26|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-04-17 15:14:52--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1594 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-17 15:14:53 (34.0 MB/s) - written to stdout [1594/1594]\n",
            "\n",
            "setup Colab for PySpark 3.0.2 and Spark NLP 3.0.1\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 38kB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 52.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 22.9MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jHkahKTiRVt"
      },
      "source": [
        "import pandas as pd\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import StringType,StructType,StructField,IntegerType\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import json\n",
        "class BuildModel:\n",
        "  def __init__(self,path):\n",
        "    self.spark = sparknlp.start()\n",
        "    self.prepare_data(path)\n",
        "    self.load_pipe_components()\n",
        "    self.create_fin_pipeline()\n",
        "    self.evaluation()\n",
        "    \n",
        "  def process(self):\n",
        "    l = []\n",
        "    for i in range(len(self.fin_tfolds)):\n",
        "      print('ROUND '+str(i)+' started')\n",
        "      l.append(self.run_training(self.fin_tfolds[i],self.fin_vfolds[i],i))\n",
        "      print('ROUND '+str(i)+' completed')\n",
        "    return l  \n",
        "\n",
        "    \n",
        "  def prepare_data(self,path):\n",
        "    df = pd.read_csv(path)\n",
        "    if 'sarcasm' in list(df.columns):\n",
        "      df = df.drop('sarcasm',axis=1)\n",
        "      df = df.rename({'sar_num':'target'})\n",
        "    elif 'final_sent_class' in list(df.columns):\n",
        "      df = df.drop('final_sent_class',axis=1)\n",
        "      df = df.rename({'sentiment':'target'})\n",
        "          \n",
        "    tfolds = [df[df.kfold != fold].drop('kfold',axis=1).reset_index(drop=True) for fold in range(5)]\n",
        "    vfolds = [df[df.kfold == fold].drop('kfold',axis=1).reset_index(drop=True) for fold in range(5)]\n",
        "    schema = StructType([StructField('id', StringType(), True),                     \n",
        "                      StructField('text', StringType(), True),\n",
        "                      StructField('label', IntegerType(), True)])\n",
        "                      \n",
        "    self.fin_tfolds = [self.spark.createDataFrame(data,schema) for data in tfolds]\n",
        "    self.fin_vfolds = [self.spark.createDataFrame(data,schema) for data in vfolds]\n",
        "    \n",
        "  def load_pipe_components(self):\n",
        "    self.document = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "    # self.tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
        "    # self.spellModel = ContextSpellCheckerModel.pretrained().setInputCols(\"token\").setOutputCol(\"spell\")\n",
        "    # self.lemmatizer = LemmatizerModel.pretrained(name=\"lemma_antbnc\").setInputCols([\"spell\"]).setOutputCol(\"lemma\").setLazyAnnotator(False)\n",
        "    self.sentenceDetector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
        "    self.use = UniversalSentenceEncoder.pretrained().setInputCols([\"sentence\"]).setOutputCol(\"embeddings\")\n",
        "    # self.embeddings = BertEmbeddings.pretrained(\"small_bert_L12_128\", \"en\").setInputCols(\"sentence\", \"lemma\").setOutputCol(\"embeddings\")\n",
        "    # self.sen_emb = SentenceEmbeddings().setInputCols([\"document\",\"embeddings\"]).setOutputCol(\"sen_emb\").setPoolingStrategy(\"AVERAGE\")\n",
        "    self.embeddings_finisher = EmbeddingsFinisher().setInputCols(\"embeddings\").setOutputCols(\"embeddings_vectors\").setCleanAnnotations(True).setOutputAsVector(True)\n",
        "    # self.assembler = VectorAssembler(inputCols=['embeddings_vectors'],outputCol='features')\n",
        "    self.ml = LogisticRegression(featuresCol='input',labelCol='label')\n",
        "    \n",
        "    \n",
        "    #vec_assembler\n",
        "    #ml model\n",
        "\n",
        "  def create_fin_pipeline(self):\n",
        "    \n",
        "    self.nlp_pipeline = Pipeline(stages = [\n",
        "          self.document,\n",
        "          # self.tokenizer,\n",
        "          # self.spellModel,\n",
        "          # self.lemmatizer,\n",
        "          self.sentenceDetector,\n",
        "          self.use,\n",
        "          # self.embeddings,\n",
        "          # self.sen_emb,\n",
        "          self.embeddings_finisher\n",
        "          # self.assembler,\n",
        "          ])\n",
        "    self.ml_pipeline = Pipeline(stages = [self.ml])\n",
        "  \n",
        "\n",
        "  def run_training(self,df_tr,df_val,i):\n",
        "    df_tr_emb = self.nlp_pipeline.fit(df_tr).transform(df_tr)\n",
        "    df_tr_emb = df_tr_emb.select('id',F.explode('embeddings_vectors').alias('input'),'label')\n",
        "    self.model = self.ml_pipeline.fit(df_tr_emb)\n",
        "    df_val_emb = self.nlp_pipeline.fit(df_val).transform(df_val)\n",
        "    df_val_emb = df_val_emb.select('id',F.explode('embeddings_vectors').alias('input'))\n",
        "    df_res = self.model.transform(df_val_emb)\n",
        "    df_eval = df_res.join(df_val,on='id',how='inner').select('label','prediction')\n",
        "    acc = self.evaluator.evaluate(df_eval, {self.evaluator.metricName: \"accuracy\"})\n",
        "    f1 = self.evaluator.evaluate(df_eval, {self.evaluator.metricName: \"f1\"})\n",
        "    weightedPrecision = self.evaluator.evaluate(df_eval, {self.evaluator.metricName: \"weightedPrecision\"})\n",
        "    weightedRecall = self.evaluator.evaluate(df_eval, {self.evaluator.metricName: \"weightedRecall\"})\n",
        "\n",
        "    return {'accuracy': acc,'f1':f1,'weighted precision': weightedPrecision,'weighted recall':weightedRecall}\n",
        "    \n",
        "  def evaluation(self):\n",
        "    self.evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "    \n",
        "  def save(self):\n",
        "    return self.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZdridPujD4e",
        "outputId": "381d29d9-bf65-4995-8234-c21633917d0d"
      },
      "source": [
        "bm = BuildModel('/content/drive/MyDrive/sarcasm data/train_sarc_final_with_folds.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfuFX6ZphR3H"
      },
      "source": [
        "df_pan = pd.read_csv('/content/drive/MyDrive/sarcasm data/train_sarc_final_with_folds.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcRaZGm6hdLn"
      },
      "source": [
        "x_tr = df_pan[df_pan['kfold']!=0]\n",
        "x_val = df_pan[df_pan['kfold']==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbXHaqP1hsDB"
      },
      "source": [
        "x_tr = x_tr.drop(['sarcasm','kfold'],axis = 1)\n",
        "x_val = x_val.drop(['sarcasm','kfold'],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbpJroB5lGUh",
        "outputId": "e42259ac-6ece-419a-e098-ac9e7d39ecf1"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import StringType,StructType,StructField,IntegerType\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.linalg import VectorUDT, DenseVector\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "import time\n",
        "prog_start_time = time.time()\n",
        "import json\n",
        "\n",
        "spark = sparknlp.start(gpu=True) \n",
        "schema_sarc = StructType([StructField('id', StringType(), True),                     \n",
        "                      StructField('text', StringType(), True),\n",
        "                      StructField('label', IntegerType(), True)])\n",
        "\n",
        "\n",
        "# df_pan = pd.read_csv('/content/drive/MyDrive/sarcasm data/train_sarc_final.csv')\n",
        "# df_src = df_pan[df_pan['sarcasm']=='sarcasm'].sample(n=50000)\n",
        "# df_nsrc = df_pan[df_pan['sarcasm']=='normal'].sample(n=50000)\n",
        "\n",
        "# df_pan = pd.concat([df_src,df_nsrc],ignore_index=True)\n",
        "# df_pan = df_pan.sample(frac=1).reset_index(drop=True)\n",
        "# d = {'sarcasm':1,'normal':0}\n",
        "# df_pan['label'] = df_pan['sarcasm'].apply(lambda x: d[x])\n",
        "# df_pan = df_pan.drop('sarcasm',axis = 1)\n",
        "# x_tr,x_ts,y_tr,y_ts = train_test_split(df_pan.drop('label',axis = 1),df_pan['label'],test_size=0.25,stratify=df_pan['label'])\n",
        "# # print(x_tr.columns)\n",
        "# x_tr['label'] = y_tr\n",
        "# x_ts['label'] = y_ts \n",
        "df_sp = spark.createDataFrame(df,schema_sarc)\n",
        "\n",
        "document = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "\n",
        "# tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
        "# spellModel = ContextSpellCheckerModel.pretrained().setInputCols(\"token\").setOutputCol(\"spell\")\n",
        "\n",
        "sentenceDetector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
        "use = UniversalSentenceEncoder.pretrained().setInputCols([\"sentence\"]).setOutputCol(\"embeddings\")\n",
        "# embeddings = BertSentenceEmbeddings.pretrained(\"sent_electra_small_uncased\", \"en\").setInputCols([\"sentence\",\"spell\"]).setOutputCol(\"embeddings\")\n",
        "embeddings_finisher = EmbeddingsFinisher().setInputCols(\"embeddings\").setOutputCols(\"embeddings_vectors\").setCleanAnnotations(True).setOutputAsVector(True)\n",
        "# ml = LogisticRegression(featuresCol='input',labelCol='label')\n",
        "lemm_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        # tokenizer,\n",
        "        # spellModel,\n",
        "       #  lemmatizer,\n",
        "        sentenceDetector,\n",
        "        use,\n",
        "\t\tembeddings_finisher\n",
        "        # spell_checker,\n",
        "#         lemmatizer\n",
        "    ])\n",
        "\n",
        "ml_pipeline = Pipeline(stages = [ml])\n",
        "df_emb = lemm_pipeline.fit(df_sp).transform(df_sp)\n",
        "# df_emb_ts = lemm_pipeline.fit(df_ts).transform(df_ts)\n",
        "df_emb = df_emb.select('id',F.explode('embeddings_vectors').alias('input'),'label')\n",
        "# df_emb_ts = df_emb_ts.select('id',F.explode('embeddings_vectors').alias('input'),'label')\n",
        "\n",
        "model = ml_pipeline.fit(df_emb)\n",
        "# df_res = model.transform(df_emb_ts.drop('label'))\n",
        "# df_eval = df_res.join(df_emb_ts,on='id',how='inner').select('label','prediction')\n",
        "# evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# acc = evaluator.evaluate(df_eval, {evaluator.metricName: \"accuracy\"})\n",
        "# f1 = evaluator.evaluate(df_eval, {evaluator.metricName: \"f1\"})\n",
        "# weightedPrecision = evaluator.evaluate(df_eval, {evaluator.metricName: \"weightedPrecision\"})\n",
        "# weightedRecall = evaluator.evaluate(df_eval, {evaluator.metricName: \"weightedRecall\"})\n",
        " \n",
        "# smry = {'accuracy': acc,'f1':f1,'weighted precision': weightedPrecision,'weighted recall':weightedRecall}\n",
        "# print(smry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC9k2NQQej-y",
        "outputId": "637357da-e4e2-488a-878a-267ec7e614d1"
      },
      "source": [
        "x = bm.process()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROUND 0 started\n",
            "ROUND 0 completed\n",
            "ROUND 1 started\n",
            "ROUND 1 completed\n",
            "ROUND 2 started\n",
            "ROUND 2 completed\n",
            "ROUND 3 started\n",
            "ROUND 3 completed\n",
            "ROUND 4 started\n",
            "ROUND 4 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LXHQCy41j7R"
      },
      "source": [
        "mod = bm.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJMI-zwz2IPB"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/sarcasm data/train_sarc_final_with_folds.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d6IuNR13OUB"
      },
      "source": [
        "schema_sarc = StructType([StructField('id', StringType(), True),                     \n",
        "                      StructField('text', StringType(), True),\n",
        "                      StructField('label', IntegerType(), True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8bwTY2I3SNT"
      },
      "source": [
        "df = df.drop(['sarcasm','kfold'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glFXvTSD4Xol",
        "outputId": "bf2b6a39-1a16-4f25-81a0-760a2d8ad103"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['u_id', 'preprocessed', 'sar_num'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vUbNqYU1v9w",
        "outputId": "7c146c18-e2fb-4028-f3c6-bf110bb8e3b7"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PipelineModel_8e899af0a6c8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHRcFDgSbYlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25bff71d-739d-48a0-b358-13a23a1f1b4a"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 0.9837244897959184,\n",
              "  'f1': 0.9837241491575145,\n",
              "  'weighted precision': 0.9837649887990588,\n",
              "  'weighted recall': 0.9837244897959183},\n",
              " {'accuracy': 0.9834013605442177,\n",
              "  'f1': 0.9834010157210402,\n",
              "  'weighted precision': 0.9834415321215734,\n",
              "  'weighted recall': 0.9834013605442177},\n",
              " {'accuracy': 0.9838775510204082,\n",
              "  'f1': 0.9838772548883551,\n",
              "  'weighted precision': 0.9839131038198725,\n",
              "  'weighted recall': 0.9838775510204081},\n",
              " {'accuracy': 0.9836734693877551,\n",
              "  'f1': 0.9836730443837043,\n",
              "  'weighted precision': 0.9837238363011559,\n",
              "  'weighted recall': 0.9836734693877551},\n",
              " {'accuracy': 0.9838945578231293,\n",
              "  'f1': 0.9838942207441654,\n",
              "  'weighted precision': 0.9839350710649235,\n",
              "  'weighted recall': 0.9838945578231293}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}