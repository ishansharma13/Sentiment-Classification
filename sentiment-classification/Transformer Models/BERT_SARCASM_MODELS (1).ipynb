{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT SARCASM MODELS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrffzMfCGLk_",
        "outputId": "f01d4bfe-6f12-49a6-c0cb-6a50848222f6"
      },
      "source": [
        "!pip install transformers==3.0.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 5.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 25.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbwt7aY1G0J2",
        "outputId": "9ff89b9f-0dfe-4569-f888-fdaca04ddcf4"
      },
      "source": [
        "from transformers import TFBertModel\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsuoBOiOG63-",
        "outputId": "b3702e51-5b7a-43dc-cc94-8764bdef82d8"
      },
      "source": [
        "import os\n",
        "import pprint # for pretty printing our device stats\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "\n",
        "    with tf.compat.v1.Session(tpu_address) as session:\n",
        "      devices = session.list_devices()\n",
        "\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.98.155.138:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 8993880738047063576),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 2019497877551593296),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7406575394408403832),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3302880320694752244),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -7539370457473513042),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 5503163934790677228),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7923884702013318954),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -2041968936354005050),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1637475452241709548),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 5008076684440239399),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8073280149222575718)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13gULAQ2G_l_",
        "outputId": "eb25f51a-d606-4f46-e57c-fe523d80f963"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.98.155.138:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.98.155.138:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYX-aeIPHExR"
      },
      "source": [
        "class distilBertModels:\n",
        "  def __init__(self,path):\n",
        "    df = pd.read_csv(path)\n",
        "    self.max_seq_len = 35\n",
        "    bert_name = 'bert-base-uncased'\n",
        "    # self.tokenizer = AlbertTokenizer.from_pretrained(bert_name,add_special_tokens=True,max_length =self.max_seq_len,pad_to_max_length = True)\n",
        "    self.train_set,self.test_set = self.prepare_data(df)\n",
        "    with strategy.scope():\n",
        "      self.bert = TFBertModel.from_pretrained(bert_name)\n",
        "      self.bert.trainable = False\n",
        "\n",
        "  def prepare_data(self,df):\n",
        "    df['encoded'] = df['encoded'].apply(lambda x: json.loads(x))\n",
        "    df_tr = df[df['kfold']!=0].reset_index(drop=True)\n",
        "    df_ts = df[df['kfold']==0].reset_index(drop=True)\n",
        "    enc_tr = list(df_tr['encoded'])\n",
        "    enc_ts = list(df_ts['encoded'])\n",
        "    inp_ids_tr = [np.array(k[0]) for k in enc_tr]\n",
        "    att_mks_tr = [np.array(k[1]) for k in enc_tr]\n",
        "    inp_ids_ts = [np.array(k[0]) for k in enc_ts]\n",
        "    att_mks_ts = [np.array(k[1]) for k in enc_ts]\n",
        "    x_tr_inp_ids = tf.cast(tf.squeeze(tf.stack(inp_ids_tr)),dtype=tf.int32)\n",
        "    x_tr_att_mks = tf.cast(tf.squeeze(tf.stack(att_mks_tr)),dtype=tf.int32)\n",
        "    x_ts_inp_ids = tf.cast(tf.squeeze(tf.stack(inp_ids_ts)),dtype=tf.int32)\n",
        "    x_ts_att_mks = tf.cast(tf.squeeze(tf.stack(att_mks_ts)),dtype=tf.int32)\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    y_tr = np_utils.to_categorical(encoder.fit_transform(df_tr.label.values))\n",
        "    y_ts = np_utils.to_categorical(encoder.fit_transform(df_ts.label.values))\n",
        "\n",
        "    x_tr = [x_tr_inp_ids,x_tr_att_mks]\n",
        "    x_ts = [x_ts_inp_ids,x_ts_att_mks]\n",
        "\n",
        "    return ((x_tr,y_tr),(x_ts,y_ts))\n",
        "\n",
        "  # def encode_data(self,x):\n",
        "  #   encoded = self.tokenizer.encode_plus(x,add_special_tokens=True,max_length =self.max_seq_len,padding = 'max_length',truncation=True,return_attention_mask=True,return_tensors='tf')\n",
        "  #   return encoded\n",
        "  \n",
        "  def process(self,ls):\n",
        "  # for name in ls:\n",
        "#       his = self.compile_model(name)\n",
        "#       dfs = []\n",
        "#       for i in range(len(his)):\n",
        "#         df = pd.DataFrame.from_dict(his[i].history)\n",
        "#         df['fold'] = i+1\n",
        "#         df['epoch'] = [j+1 for j in range(len(df))]\n",
        "#         dfs.append(df)\n",
        "#       df_fin = pd.concat(dfs,ignore_index=True)  \n",
        "#       df_fin.to_csv('/content/drive/MyDrive/Bert/Folds/sent_'+name+'_folds.csv',index=False,header=True)\n",
        "    for name in ls:\n",
        "      his = self.compile_model(name)\n",
        "      df = pd.DataFrame.from_dict(his.history)\n",
        "      df['epoch'] = [i+1 for i in range(len(df))]\n",
        "      df.to_csv('/content/drive/MyDrive/Bert/sarcasm/sarc_'+name+'.csv',index=False,header=True)\n",
        "      print(\"\\n------------------ PROCESS FOR MODEL: \"+name+' COMPLETED ------------------\\n')\n",
        "\n",
        "\n",
        "  def compile_model(self,name):\n",
        "    with strategy.scope():\n",
        "      model = self.create_model(name)\n",
        "      model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    print('\\n------------------ '+name+' ------------------\\n')\n",
        "    model.summary()\n",
        "    # his = []\n",
        "    # for i in range(len(self.train_set_folds)):\n",
        "#       print('\\n**************** FOLD '+str(i+1)+' ****************')\n",
        "    his = model.fit(x = self.train_set[0],y = self.train_set[1],validation_data=(self.test_set[0],self.test_set[1]),epochs=100,callbacks=[EarlyStopping()])\n",
        "    print('\\n**************** TRAINING OF MODEL: '+name+' COMPLETED****************\\n')\n",
        "    return his\n",
        "    \n",
        "  def create_model(self,name):\n",
        "    inputs = tf.keras.layers.Input((self.max_seq_len,),dtype = tf.int32,name=\"input_ids\")\n",
        "    mask = tf.keras.layers.Input((self.max_seq_len,),dtype = tf.int32,name=\"attention_mask\")\n",
        "\n",
        "    pred = self.bert([inputs,mask])[0]\n",
        "\n",
        "    if name == 'BERT-CONV1D': ## 1\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(x)\n",
        "      x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "\n",
        "    \n",
        "    if name == 'BERT-CONV1D-BiGRU': ## 2\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "    \n",
        "    if name == 'BERT-CONV1D-BiLSTM': ## 3\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)    \n",
        "      \n",
        "    if name == 'BERT-CONV1D-BiRNN': ## 4\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "\n",
        "    if name == 'BERT-SEP-CONV1D': #5\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "      \n",
        "\n",
        "    if name == 'BERT-SEP-CONV1D-BiGRU': ## 6\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "      \n",
        "    if name == 'BERT-SEP-CONV1D-BiRNN': ## 7\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "      \n",
        "    if name == 'BERT-SEP-CONV1D-BiLSTM': ## 8\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "      \n",
        "      \n",
        "    if name == 'BERT-BiGRU': ## 9\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "      \n",
        "    if name == 'BERT-BiLSTM': ## 10\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "    \n",
        "    if name == 'BERT-BiRNN': ## 11\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
        "    \n",
        "      \n",
        "    return tf.keras.Model([inputs,mask],x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh-dYvXlHadF",
        "outputId": "19b41217-51ec-4c76-c786-a42f018fb00a"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "bert = distilBertModels('/content/drive/MyDrive/sarcasm data/tr_sarc_fin_bert_trans_inps.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_tf_utils:All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYa-3HT9ItYi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIeCvXcZH0Fu",
        "outputId": "6f47eef6-71a5-498f-98a4-785c9dd2af6b"
      },
      "source": [
        "bert.process(['BERT-CONV1D','BERT-CONV1D-BiGRU','BERT-CONV1D-BiLSTM','BERT-CONV1D-BiRNN','BERT-SEP-CONV1D','BERT-SEP-CONV1D-BiGRU'])\n",
        "# bert.process(['BERT-SEP-CONV1D-BiRNN','BERT-SEP-CONV1D-BiLSTM','BERT-BiGRU','BERT-BiLSTM','BERT-BiRNN'])\n",
        "# {1:'BERT-CONV1D',2:'BERT-CONV1D-BiGRU',3:'BERT-CONV1D-BiLSTM',4:'BERT-CONV1D-BiRNN',5:'BERT-SEP-CONV1D',6:'BERT-SEP-CONV1D-BiGRU',7:'BERT-SEP-CONV1D-BiRNN',8:'BERT-SEP-CONV1D-BiLSTM',9:'BERT-BiGRU',10:'BERT-BiLSTM',11:'BERT-BiRNN'}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------ BERT-CONV1D ------------------\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 35, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 35, 32)       73760       tf_bert_model_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_1 (AveragePoo (None, 17, 32)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 17, 32)       3104        average_pooling1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 32)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 32)           0           global_average_pooling1d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           660         dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,559,806\n",
            "Trainable params: 77,566\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "7350/7350 [==============================] - 212s 27ms/step - loss: 0.3993 - accuracy: 0.8190 - val_loss: 0.3427 - val_accuracy: 0.8489\n",
            "Epoch 2/100\n",
            "7350/7350 [==============================] - 179s 24ms/step - loss: 0.3475 - accuracy: 0.8452 - val_loss: 0.3289 - val_accuracy: 0.8543\n",
            "Epoch 3/100\n",
            "7350/7350 [==============================] - 182s 25ms/step - loss: 0.3301 - accuracy: 0.8537 - val_loss: 0.3163 - val_accuracy: 0.8599\n",
            "Epoch 4/100\n",
            "7350/7350 [==============================] - 182s 25ms/step - loss: 0.3213 - accuracy: 0.8582 - val_loss: 0.3157 - val_accuracy: 0.8595\n",
            "Epoch 5/100\n",
            "7350/7350 [==============================] - 181s 25ms/step - loss: 0.3143 - accuracy: 0.8621 - val_loss: 0.3088 - val_accuracy: 0.8640\n",
            "Epoch 6/100\n",
            "7350/7350 [==============================] - 180s 24ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 0.3047 - val_accuracy: 0.8650\n",
            "Epoch 7/100\n",
            "7350/7350 [==============================] - 180s 24ms/step - loss: 0.3033 - accuracy: 0.8680 - val_loss: 0.3058 - val_accuracy: 0.8666\n",
            "\n",
            "**************** TRAINING OF MODEL: BERT-CONV1D COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: BERT-CONV1D COMPLETED ------------------\n",
            "\n",
            "\n",
            "------------------ BERT-CONV1D-BiGRU ------------------\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 35, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 35, 32)       73760       tf_bert_model_1[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_2 (AveragePoo (None, 17, 32)       0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 17, 32)       4800        average_pooling1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 544)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 544)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 512)          279040      dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 128)          65664       dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 32)           4128        dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 2)            66          dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,909,698\n",
            "Trainable params: 427,458\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "7350/7350 [==============================] - 227s 28ms/step - loss: 0.4057 - accuracy: 0.8150 - val_loss: 0.3537 - val_accuracy: 0.8415\n",
            "Epoch 2/100\n",
            "7350/7350 [==============================] - 193s 26ms/step - loss: 0.3534 - accuracy: 0.8427 - val_loss: 0.3527 - val_accuracy: 0.8495\n",
            "Epoch 3/100\n",
            "7350/7350 [==============================] - 194s 26ms/step - loss: 0.3441 - accuracy: 0.8477 - val_loss: 0.3276 - val_accuracy: 0.8556\n",
            "Epoch 4/100\n",
            "7350/7350 [==============================] - 195s 27ms/step - loss: 0.3332 - accuracy: 0.8534 - val_loss: 0.3252 - val_accuracy: 0.8557\n",
            "Epoch 5/100\n",
            "7350/7350 [==============================] - 195s 27ms/step - loss: 0.3283 - accuracy: 0.8554 - val_loss: 0.3248 - val_accuracy: 0.8567\n",
            "Epoch 6/100\n",
            "7350/7350 [==============================] - 196s 27ms/step - loss: 0.3242 - accuracy: 0.8570 - val_loss: 0.3174 - val_accuracy: 0.8616\n",
            "Epoch 7/100\n",
            "7350/7350 [==============================] - 202s 28ms/step - loss: 0.3197 - accuracy: 0.8598 - val_loss: 0.3102 - val_accuracy: 0.8647\n",
            "Epoch 8/100\n",
            "7350/7350 [==============================] - 199s 27ms/step - loss: 0.3167 - accuracy: 0.8603 - val_loss: 0.3132 - val_accuracy: 0.8620\n",
            "\n",
            "**************** TRAINING OF MODEL: BERT-CONV1D-BiGRU COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: BERT-CONV1D-BiGRU COMPLETED ------------------\n",
            "\n",
            "\n",
            "------------------ BERT-CONV1D-BiLSTM ------------------\n",
            "\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 35, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 35, 32)       73760       tf_bert_model_1[2][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 17, 32)       0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 17, 32)       6272        average_pooling1d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 544)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 544)          0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 512)          279040      dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 128)          65664       dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 32)           4128        dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 2)            66          dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 109,911,170\n",
            "Trainable params: 428,930\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "7350/7350 [==============================] - 234s 29ms/step - loss: 0.4016 - accuracy: 0.8168 - val_loss: 0.3370 - val_accuracy: 0.8504\n",
            "Epoch 2/100\n",
            "7350/7350 [==============================] - 201s 27ms/step - loss: 0.3522 - accuracy: 0.8443 - val_loss: 0.3373 - val_accuracy: 0.8554\n",
            "\n",
            "**************** TRAINING OF MODEL: BERT-CONV1D-BiLSTM COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: BERT-CONV1D-BiLSTM COMPLETED ------------------\n",
            "\n",
            "\n",
            "------------------ BERT-CONV1D-BiRNN ------------------\n",
            "\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 35, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 35, 32)       73760       tf_bert_model_1[3][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 17, 32)       0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 17, 32)       1568        average_pooling1d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 544)          0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 544)          0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 512)          279040      dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 128)          65664       dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 32)           4128        dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 2)            66          dense_14[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 109,906,466\n",
            "Trainable params: 424,226\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "7350/7350 [==============================] - 224s 28ms/step - loss: 0.4110 - accuracy: 0.8116 - val_loss: 0.3471 - val_accuracy: 0.8448\n",
            "Epoch 2/100\n",
            "7350/7350 [==============================] - 192s 26ms/step - loss: 0.3592 - accuracy: 0.8401 - val_loss: 0.3590 - val_accuracy: 0.8492\n",
            "\n",
            "**************** TRAINING OF MODEL: BERT-CONV1D-BiRNN COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: BERT-CONV1D-BiRNN COMPLETED ------------------\n",
            "\n",
            "\n",
            "------------------ BERT-SEP-CONV1D ------------------\n",
            "\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 35, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d (SeparableConv (None, 35, 32)       26912       tf_bert_model_1[4][0]            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 17, 32)       0           separable_conv1d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_1 (SeparableCo (None, 17, 32)       1152        average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_6 (AveragePoo (None, 8, 32)        0           separable_conv1d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 256)          0           average_pooling1d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 256)          0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 256)          65792       dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 64)           16448       dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 16)           1040        dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 2)            34          dense_18[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 109,593,618\n",
            "Trainable params: 111,378\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "7350/7350 [==============================] - 214s 27ms/step - loss: 0.4092 - accuracy: 0.8098 - val_loss: 0.3546 - val_accuracy: 0.8389\n",
            "Epoch 2/100\n",
            "7350/7350 [==============================] - 188s 26ms/step - loss: 0.3578 - accuracy: 0.8405 - val_loss: 0.3356 - val_accuracy: 0.8505\n",
            "Epoch 3/100\n",
            "7350/7350 [==============================] - 189s 26ms/step - loss: 0.3419 - accuracy: 0.8491 - val_loss: 0.3320 - val_accuracy: 0.8522\n",
            "Epoch 4/100\n",
            "7350/7350 [==============================] - 190s 26ms/step - loss: 0.3342 - accuracy: 0.8527 - val_loss: 0.3326 - val_accuracy: 0.8519\n",
            "\n",
            "**************** TRAINING OF MODEL: BERT-SEP-CONV1D COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: BERT-SEP-CONV1D COMPLETED ------------------\n",
            "\n",
            "\n",
            "------------------ BERT-SEP-CONV1D-BiGRU ------------------\n",
            "\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 35, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_2 (SeparableCo (None, 35, 32)       26912       tf_bert_model_1[5][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 17, 32)       0           separable_conv1d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 17, 32)       4800        max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 8, 32)        0           bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 256)          0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 256)          0           flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 256)          65792       dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 64)           16448       dense_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 16)           1040        dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 2)            34          dense_22[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 109,597,266\n",
            "Trainable params: 115,026\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "7350/7350 [==============================] - 233s 29ms/step - loss: 0.4049 - accuracy: 0.8149 - val_loss: 0.3509 - val_accuracy: 0.8441\n",
            "Epoch 2/100\n",
            "7350/7350 [==============================] - 202s 28ms/step - loss: 0.3506 - accuracy: 0.8447 - val_loss: 0.3398 - val_accuracy: 0.8531\n",
            "Epoch 3/100\n",
            "7350/7350 [==============================] - 206s 28ms/step - loss: 0.3373 - accuracy: 0.8499 - val_loss: 0.3268 - val_accuracy: 0.8555\n",
            "Epoch 4/100\n",
            "7350/7350 [==============================] - 202s 28ms/step - loss: 0.3278 - accuracy: 0.8550 - val_loss: 0.3129 - val_accuracy: 0.8623\n",
            "Epoch 5/100\n",
            "7350/7350 [==============================] - 199s 27ms/step - loss: 0.3236 - accuracy: 0.8579 - val_loss: 0.3122 - val_accuracy: 0.8600\n",
            "Epoch 6/100\n",
            "7350/7350 [==============================] - 205s 28ms/step - loss: 0.3182 - accuracy: 0.8602 - val_loss: 0.3084 - val_accuracy: 0.8614\n",
            "Epoch 7/100\n",
            "7350/7350 [==============================] - 202s 28ms/step - loss: 0.3124 - accuracy: 0.8634 - val_loss: 0.3070 - val_accuracy: 0.8648\n",
            "Epoch 8/100\n",
            "7350/7350 [==============================] - 201s 27ms/step - loss: 0.3081 - accuracy: 0.8644 - val_loss: 0.3120 - val_accuracy: 0.8614\n",
            "\n",
            "**************** TRAINING OF MODEL: BERT-SEP-CONV1D-BiGRU COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: BERT-SEP-CONV1D-BiGRU COMPLETED ------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}