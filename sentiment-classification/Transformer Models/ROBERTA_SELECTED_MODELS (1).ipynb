{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ROBERTA SELECTED MODELS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dee2ffe3d9384e299a4d9aa1d4fac8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a82069d2ddfd4eeda669e739ed71d6ee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_909c0a0cdbe74333af6a2bea90b777a4",
              "IPY_MODEL_c7ae3ccee4f7418e9f909f833b7dea00"
            ]
          }
        },
        "a82069d2ddfd4eeda669e739ed71d6ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "909c0a0cdbe74333af6a2bea90b777a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b51a7b9de4b43beb6741b1985b02335",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3d8572572884b6fb8b4e8ade0e481ca"
          }
        },
        "c7ae3ccee4f7418e9f909f833b7dea00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50b522e6472c478c98d9dbfd1ba7caf0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:16&lt;00:00, 28.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20a22507f5c9407ab5e830726e21579f"
          }
        },
        "4b51a7b9de4b43beb6741b1985b02335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3d8572572884b6fb8b4e8ade0e481ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50b522e6472c478c98d9dbfd1ba7caf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20a22507f5c9407ab5e830726e21579f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfb83e04356146d8a7e30dafb37297bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fec6676bd47648ccb09b2a59ac345fe0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_218a36c0fd1b48b298c426febba0c8ca",
              "IPY_MODEL_64f21ec82b094ac1aa0aa462e693140e"
            ]
          }
        },
        "fec6676bd47648ccb09b2a59ac345fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "218a36c0fd1b48b298c426febba0c8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e60e526733ac4120b8293bf5f8cc00bc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 657434796,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 657434796,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_836af29f2248491c955c17bddcbc3b87"
          }
        },
        "64f21ec82b094ac1aa0aa462e693140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18a4227bf825475880c950ab3c7fcf93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 657M/657M [00:16&lt;00:00, 40.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_004fd33705b04309bcf31d3f26f83e43"
          }
        },
        "e60e526733ac4120b8293bf5f8cc00bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "836af29f2248491c955c17bddcbc3b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18a4227bf825475880c950ab3c7fcf93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "004fd33705b04309bcf31d3f26f83e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jfm375aaGjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2737e2a0-d16a-4ae6-9edd-be9d9ba62dc1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 23.0MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEhE1wd7aP1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66cb9fe8-38e3-48d0-be9c-9ef41789ab2a"
      },
      "source": [
        "from transformers import TFRobertaModel\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "import json\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvVWzugUaR81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc4d708-f7fa-4485-e394-97e6cdb54534"
      },
      "source": [
        "import os\n",
        "import pprint # for pretty printing our device stats\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "\n",
        "    with tf.compat.v1.Session(tpu_address) as session:\n",
        "      devices = session.list_devices()\n",
        "\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.16.87.26:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, -8018179368005066931),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6799895761180849216),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3798198207115989096),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7267526605667031065),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -6697222060864987744),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6207360207148476955),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1563816933492268087),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 262015872627137203),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -7713893159689645976),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1692973024144070004),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -6998030491730417761)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQU1cGvfaUPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59dccafb-c909-4a7b-ab69-813099dade02"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.87.26:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.87.26:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMmHuPH5aWZe"
      },
      "source": [
        "class distilBertModels:\n",
        "  def __init__(self,path):\n",
        "    df = pd.read_csv(path)\n",
        "    self.max_seq_len = 35\n",
        "    bert_name = 'roberta-base'\n",
        "    # self.tokenizer = AlbertTokenizer.from_pretrained(bert_name,add_special_tokens=True,max_length =self.max_seq_len,pad_to_max_length = True)\n",
        "    self.train_set,self.test_set = self.prepare_data(df)\n",
        "    with strategy.scope():\n",
        "      self.bert = TFRobertaModel.from_pretrained(bert_name)\n",
        "      self.bert.trainable = False\n",
        "\n",
        "  def prepare_data(self,df):\n",
        "    df['encoded'] = df['encoded'].apply(lambda x: json.loads(x))\n",
        "    df_tr = df[df['kfold']!=0].reset_index(drop=True)\n",
        "    df_ts = df[df['kfold']==0].reset_index(drop=True)\n",
        "    enc_tr = list(df_tr['encoded'])\n",
        "    enc_ts = list(df_ts['encoded'])\n",
        "    inp_ids_tr = [np.array(k[0]) for k in enc_tr]\n",
        "    att_mks_tr = [np.array(k[1]) for k in enc_tr]\n",
        "    inp_ids_ts = [np.array(k[0]) for k in enc_ts]\n",
        "    att_mks_ts = [np.array(k[1]) for k in enc_ts]\n",
        "    x_tr_inp_ids = tf.cast(tf.squeeze(tf.stack(inp_ids_tr)),dtype=tf.int32)\n",
        "    x_tr_att_mks = tf.cast(tf.squeeze(tf.stack(att_mks_tr)),dtype=tf.int32)\n",
        "    x_ts_inp_ids = tf.cast(tf.squeeze(tf.stack(inp_ids_ts)),dtype=tf.int32)\n",
        "    x_ts_att_mks = tf.cast(tf.squeeze(tf.stack(att_mks_ts)),dtype=tf.int32)\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    y_tr = np_utils.to_categorical(encoder.fit_transform(df_tr.label.values))\n",
        "    y_ts = np_utils.to_categorical(encoder.fit_transform(df_ts.label.values))\n",
        "\n",
        "    x_tr = [x_tr_inp_ids,x_tr_att_mks]\n",
        "    x_ts = [x_ts_inp_ids,x_ts_att_mks]\n",
        "\n",
        "    return ((x_tr,y_tr),(x_ts,y_ts))\n",
        "\n",
        "  # def encode_data(self,x):\n",
        "  #   encoded = self.tokenizer.encode_plus(x,add_special_tokens=True,max_length =self.max_seq_len,padding = 'max_length',truncation=True,return_attention_mask=True,return_tensors='tf')\n",
        "  #   return encoded\n",
        "  \n",
        "  def process(self,ls):\n",
        "  # for name in ls:\n",
        "#       his = self.compile_model(name)\n",
        "#       dfs = []\n",
        "#       for i in range(len(his)):\n",
        "#         df = pd.DataFrame.from_dict(his[i].history)\n",
        "#         df['fold'] = i+1\n",
        "#         df['epoch'] = [j+1 for j in range(len(df))]\n",
        "#         dfs.append(df)\n",
        "#       df_fin = pd.concat(dfs,ignore_index=True)  \n",
        "#       df_fin.to_csv('/content/drive/MyDrive/Bert/Folds/sent_'+name+'_folds.csv',index=False,header=True)\n",
        "    for name in ls:\n",
        "      his = self.compile_model(name)\n",
        "      df = pd.DataFrame.from_dict(his.history)\n",
        "      df['epoch'] = [i+1 for i in range(len(df))]\n",
        "      df.to_csv('/content/drive/MyDrive/ROBERTA/Selected/sent_'+name+'.csv',index=False,header=True)\n",
        "      print(\"\\n------------------ PROCESS FOR MODEL: \"+name+' COMPLETED ------------------\\n')\n",
        "\n",
        "\n",
        "  def compile_model(self,name):\n",
        "    with strategy.scope():\n",
        "      model = self.create_model(name)\n",
        "      model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    print('\\n------------------ '+name+' ------------------\\n')\n",
        "    model.summary()\n",
        "    # his = []\n",
        "    # for i in range(len(self.train_set_folds)):\n",
        "#       print('\\n**************** FOLD '+str(i+1)+' ****************')\n",
        "    his = model.fit(x = self.train_set[0],y = self.train_set[1],validation_data=(self.test_set[0],self.test_set[1]),epochs=100,callbacks=[EarlyStopping()])\n",
        "    print('\\n**************** TRAINING OF MODEL: '+name+' COMPLETED****************\\n')\n",
        "    return his\n",
        "    \n",
        "  def create_model(self,name):\n",
        "    inputs = tf.keras.layers.Input((self.max_seq_len,),dtype = tf.int32,name=\"input_ids\")\n",
        "    mask = tf.keras.layers.Input((self.max_seq_len,),dtype = tf.int32,name=\"attention_mask\")\n",
        "\n",
        "    pred = self.bert([inputs,mask])[0]\n",
        "\n",
        "    if name == 'ROBERTA-CONV1D': ## 1\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(x)\n",
        "      x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\n",
        "    \n",
        "    if name == 'ROBERTA-CONV1D-BiGRU': ## 2\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "    \n",
        "    if name == 'ROBERTA-CONV1D-BiLSTM': ## 3\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)    \n",
        "      \n",
        "    if name == 'ROBERTA-CONV1D-BiRNN': ## 4\n",
        "      x = tf.keras.layers.Conv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "\n",
        "    if name == 'ROBERTA-SEP-CONV1D': #5\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(x)\n",
        "      x = tf.keras.layers.AveragePooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "      \n",
        "\n",
        "    if name == 'ROBERTA-SEP-CONV1D-BiGRU': ## 6\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "      \n",
        "    if name == 'ROBERTA-SEP-CONV1D-BiRNN': ## 7\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "      \n",
        "    if name == 'ROBERTA-SEP-CONV1D-BiLSTM': ## 8\n",
        "      x = tf.keras.layers.SeparableConv1D(32,3,activation='relu',padding='same')(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(x)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "      \n",
        "      \n",
        "    if name == 'ROBERTA-BiGRU': ## 9\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "      \n",
        "    if name == 'ROBERTA-BiLSTM': ## 10\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "    \n",
        "    if name == 'ROBERTA-BiRNN': ## 11\n",
        "      x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(16,return_sequences=True,dropout=0.2,recurrent_dropout=0.3))(pred)\n",
        "      x = tf.keras.layers.MaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      x = tf.keras.layers.Dropout(0.2)(x)\n",
        "      x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
        "      x = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
        "    \n",
        "      \n",
        "    return tf.keras.Model([inputs,mask],x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPHS8RVlaZIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "dee2ffe3d9384e299a4d9aa1d4fac8e9",
            "a82069d2ddfd4eeda669e739ed71d6ee",
            "909c0a0cdbe74333af6a2bea90b777a4",
            "c7ae3ccee4f7418e9f909f833b7dea00",
            "4b51a7b9de4b43beb6741b1985b02335",
            "a3d8572572884b6fb8b4e8ade0e481ca",
            "50b522e6472c478c98d9dbfd1ba7caf0",
            "20a22507f5c9407ab5e830726e21579f",
            "dfb83e04356146d8a7e30dafb37297bf",
            "fec6676bd47648ccb09b2a59ac345fe0",
            "218a36c0fd1b48b298c426febba0c8ca",
            "64f21ec82b094ac1aa0aa462e693140e",
            "e60e526733ac4120b8293bf5f8cc00bc",
            "836af29f2248491c955c17bddcbc3b87",
            "18a4227bf825475880c950ab3c7fcf93",
            "004fd33705b04309bcf31d3f26f83e43"
          ]
        },
        "outputId": "d3448b1d-7ffc-445a-f477-d7aabbde98a1"
      },
      "source": [
        "bert = distilBertModels('/content/drive/MyDrive/sentiment data/tr_sen_fin_rob_bert_trans_inps.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dee2ffe3d9384e299a4d9aa1d4fac8e9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfb83e04356146d8a7e30dafb37297bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=657434796.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2YacO79ab-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17822bf-cb4d-4c83-b363-7ab0b6ca1bc4"
      },
      "source": [
        "bert.process(['ROBERTA-CONV1D','ROBERTA-CONV1D-BiGRU','ROBERTA-CONV1D-BiLSTM','ROBERTA-CONV1D-BiRNN','ROBERTA-SEP-CONV1D','ROBERTA-SEP-CONV1D-BiGRU'])\n",
        "# bert.process(['ROBERTA-SEP-CONV1D-BiRNN','ROBERTA-SEP-CONV1D-BiLSTM','ROBERTA-BiGRU','ROBERTA-BiLSTM','ROBERTA-BiRNN'])\n",
        "# {1:'ROBERTA-CONV1D',2:'ROBERTA-CONV1D-BiGRU',3:'ROBERTA-CONV1D-BiLSTM',4:'ROBERTA-CONV1D-BiRNN',5:'ROBERTA-SEP-CONV1D',6:'ROBERTA-SEP-CONV1D-BiGRU',7:'ROBERTA-SEP-CONV1D-BiRNN',8:'ROBERTA-SEP-CONV1D-BiLSTM',9:'ROBERTA-BiGRU',10:'ROBERTA-BiLSTM',11:'ROBERTA-BiRNN'}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa432b28d00>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa432b28d00>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa432b28d00>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fa44e3d5d40> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fa44e3d5d40> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fa44e3d5d40> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------ ROBERTA-CONV1D ------------------\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 35, 32)       73760       tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 17, 32)       0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 17, 32)       3104        average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 32)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 32)           0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           660         dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 5)            105         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 124,723,261\n",
            "Trainable params: 77,629\n",
            "Non-trainable params: 124,645,632\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - ETA: 0s - loss: 0.9133 - accuracy: 0.6378WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - 437s 24ms/step - loss: 0.9133 - accuracy: 0.6378 - val_loss: 0.6780 - val_accuracy: 0.7464\n",
            "Epoch 2/100\n",
            "17250/17250 [==============================] - 413s 24ms/step - loss: 0.7079 - accuracy: 0.7327 - val_loss: 0.6241 - val_accuracy: 0.7695\n",
            "Epoch 3/100\n",
            "17250/17250 [==============================] - 414s 24ms/step - loss: 0.6647 - accuracy: 0.7521 - val_loss: 0.6039 - val_accuracy: 0.7768\n",
            "Epoch 4/100\n",
            "17250/17250 [==============================] - 415s 24ms/step - loss: 0.6413 - accuracy: 0.7608 - val_loss: 0.6097 - val_accuracy: 0.7750\n",
            "\n",
            "**************** TRAINING OF MODEL: ROBERTA-CONV1D COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: ROBERTA-CONV1D COMPLETED ------------------\n",
            "\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------ ROBERTA-CONV1D-BiGRU ------------------\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 35, 32)       73760       tf_roberta_model[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_1 (AveragePoo (None, 17, 32)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 17, 32)       4800        average_pooling1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 544)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 544)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          279040      dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 128)          65664       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 32)           4128        dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 5)            165         dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 125,073,189\n",
            "Trainable params: 427,557\n",
            "Non-trainable params: 124,645,632\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17248/17250 [============================>.] - ETA: 0s - loss: 0.8988 - accuracy: 0.6450WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - 474s 26ms/step - loss: 0.8988 - accuracy: 0.6450 - val_loss: 0.6760 - val_accuracy: 0.7471\n",
            "Epoch 2/100\n",
            "17250/17250 [==============================] - 442s 26ms/step - loss: 0.7104 - accuracy: 0.7318 - val_loss: 0.6384 - val_accuracy: 0.7618\n",
            "Epoch 3/100\n",
            "17250/17250 [==============================] - 445s 26ms/step - loss: 0.6771 - accuracy: 0.7465 - val_loss: 0.6205 - val_accuracy: 0.7707\n",
            "Epoch 4/100\n",
            "17250/17250 [==============================] - 443s 26ms/step - loss: 0.6601 - accuracy: 0.7542 - val_loss: 0.6231 - val_accuracy: 0.7675\n",
            "\n",
            "**************** TRAINING OF MODEL: ROBERTA-CONV1D-BiGRU COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: ROBERTA-CONV1D-BiGRU COMPLETED ------------------\n",
            "\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------ ROBERTA-CONV1D-BiLSTM ------------------\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 35, 32)       73760       tf_roberta_model[2][0]           \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_2 (AveragePoo (None, 17, 32)       0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 17, 32)       6272        average_pooling1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 544)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 544)          0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 512)          279040      dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 128)          65664       dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 32)           4128        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 5)            165         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 125,074,661\n",
            "Trainable params: 429,029\n",
            "Non-trainable params: 124,645,632\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - ETA: 0s - loss: 0.8898 - accuracy: 0.6469WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - 476s 26ms/step - loss: 0.8898 - accuracy: 0.6469 - val_loss: 0.6645 - val_accuracy: 0.7507\n",
            "Epoch 2/100\n",
            "17250/17250 [==============================] - 448s 26ms/step - loss: 0.7025 - accuracy: 0.7347 - val_loss: 0.6238 - val_accuracy: 0.7701\n",
            "Epoch 3/100\n",
            "17250/17250 [==============================] - 451s 26ms/step - loss: 0.6675 - accuracy: 0.7493 - val_loss: 0.6227 - val_accuracy: 0.7702\n",
            "Epoch 4/100\n",
            "17250/17250 [==============================] - 449s 26ms/step - loss: 0.6455 - accuracy: 0.7586 - val_loss: 0.5983 - val_accuracy: 0.7804\n",
            "Epoch 5/100\n",
            "17250/17250 [==============================] - 449s 26ms/step - loss: 0.6364 - accuracy: 0.7623 - val_loss: 0.5815 - val_accuracy: 0.7846\n",
            "Epoch 6/100\n",
            "17250/17250 [==============================] - 449s 26ms/step - loss: 0.6264 - accuracy: 0.7666 - val_loss: 0.5859 - val_accuracy: 0.7842\n",
            "\n",
            "**************** TRAINING OF MODEL: ROBERTA-CONV1D-BiLSTM COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: ROBERTA-CONV1D-BiLSTM COMPLETED ------------------\n",
            "\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------ ROBERTA-CONV1D-BiRNN ------------------\n",
            "\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 35, 32)       73760       tf_roberta_model[3][0]           \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 17, 32)       0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 17, 32)       1568        average_pooling1d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 544)          0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 544)          0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 512)          279040      dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 128)          65664       dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 32)           4128        dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 5)            165         dense_12[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 125,069,957\n",
            "Trainable params: 424,325\n",
            "Non-trainable params: 124,645,632\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - ETA: 0s - loss: 0.9509 - accuracy: 0.6189WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - 462s 26ms/step - loss: 0.9509 - accuracy: 0.6189 - val_loss: 0.7346 - val_accuracy: 0.7221\n",
            "Epoch 2/100\n",
            "17250/17250 [==============================] - 436s 25ms/step - loss: 0.7591 - accuracy: 0.7108 - val_loss: 0.6731 - val_accuracy: 0.7492\n",
            "Epoch 3/100\n",
            "17250/17250 [==============================] - 435s 25ms/step - loss: 0.7222 - accuracy: 0.7257 - val_loss: 0.6553 - val_accuracy: 0.7545\n",
            "Epoch 4/100\n",
            "17250/17250 [==============================] - 435s 25ms/step - loss: 0.7006 - accuracy: 0.7362 - val_loss: 0.6283 - val_accuracy: 0.7665\n",
            "Epoch 5/100\n",
            "17250/17250 [==============================] - 434s 25ms/step - loss: 0.6899 - accuracy: 0.7416 - val_loss: 0.6179 - val_accuracy: 0.7712\n",
            "Epoch 6/100\n",
            "17250/17250 [==============================] - 435s 25ms/step - loss: 0.6826 - accuracy: 0.7451 - val_loss: 0.6448 - val_accuracy: 0.7614\n",
            "\n",
            "**************** TRAINING OF MODEL: ROBERTA-CONV1D-BiRNN COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: ROBERTA-CONV1D-BiRNN COMPLETED ------------------\n",
            "\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------ ROBERTA-SEP-CONV1D ------------------\n",
            "\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d (SeparableConv (None, 35, 32)       26912       tf_roberta_model[4][0]           \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_4 (AveragePoo (None, 17, 32)       0           separable_conv1d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_1 (SeparableCo (None, 17, 32)       1152        average_pooling1d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_5 (AveragePoo (None, 8, 32)        0           separable_conv1d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 256)          0           average_pooling1d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 256)          0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 256)          65792       dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 64)           16448       dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 16)           1040        dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 5)            85          dense_16[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 124,757,061\n",
            "Trainable params: 111,429\n",
            "Non-trainable params: 124,645,632\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17248/17250 [============================>.] - ETA: 0s - loss: 0.9408 - accuracy: 0.6193WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - 453s 25ms/step - loss: 0.9408 - accuracy: 0.6193 - val_loss: 0.7173 - val_accuracy: 0.7278\n",
            "Epoch 2/100\n",
            "17250/17250 [==============================] - 424s 25ms/step - loss: 0.7033 - accuracy: 0.7354 - val_loss: 0.6413 - val_accuracy: 0.7629\n",
            "Epoch 3/100\n",
            "17250/17250 [==============================] - 426s 25ms/step - loss: 0.6591 - accuracy: 0.7538 - val_loss: 0.6170 - val_accuracy: 0.7706\n",
            "Epoch 4/100\n",
            "17250/17250 [==============================] - 428s 25ms/step - loss: 0.6414 - accuracy: 0.7617 - val_loss: 0.6100 - val_accuracy: 0.7758\n",
            "Epoch 5/100\n",
            "17250/17250 [==============================] - 428s 25ms/step - loss: 0.6299 - accuracy: 0.7648 - val_loss: 0.5899 - val_accuracy: 0.7827\n",
            "Epoch 6/100\n",
            "17250/17250 [==============================] - 428s 25ms/step - loss: 0.6210 - accuracy: 0.7692 - val_loss: 0.5956 - val_accuracy: 0.7809\n",
            "\n",
            "**************** TRAINING OF MODEL: ROBERTA-SEP-CONV1D COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: ROBERTA-SEP-CONV1D COMPLETED ------------------\n",
            "\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------ ROBERTA-SEP-CONV1D-BiGRU ------------------\n",
            "\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 35)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_2 (SeparableCo (None, 35, 32)       26912       tf_roberta_model[5][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 17, 32)       0           separable_conv1d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 17, 32)       4800        max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 8, 32)        0           bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 256)          0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 256)          0           flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 256)          65792       dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 64)           16448       dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 16)           1040        dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 5)            85          dense_20[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 124,760,709\n",
            "Trainable params: 115,077\n",
            "Non-trainable params: 124,645,632\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - ETA: 0s - loss: 0.9277 - accuracy: 0.6259WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17250/17250 [==============================] - 490s 27ms/step - loss: 0.9277 - accuracy: 0.6259 - val_loss: 0.6888 - val_accuracy: 0.7404\n",
            "Epoch 2/100\n",
            "17250/17250 [==============================] - 453s 26ms/step - loss: 0.7031 - accuracy: 0.7349 - val_loss: 0.6274 - val_accuracy: 0.7681\n",
            "Epoch 3/100\n",
            "17250/17250 [==============================] - 454s 26ms/step - loss: 0.6637 - accuracy: 0.7517 - val_loss: 0.6359 - val_accuracy: 0.7673\n",
            "\n",
            "**************** TRAINING OF MODEL: ROBERTA-SEP-CONV1D-BiGRU COMPLETED****************\n",
            "\n",
            "\n",
            "------------------ PROCESS FOR MODEL: ROBERTA-SEP-CONV1D-BiGRU COMPLETED ------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}